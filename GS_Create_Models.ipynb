{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb\n",
    "https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb (Logit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models\n",
    "\n",
    "### Data Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team DF\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1296 entries, 0 to 1323\n",
      "Data columns (total 42 columns):\n",
      "Unnamed: 0    1296 non-null int64\n",
      "yearID        1296 non-null int64\n",
      "Rank          1296 non-null int64\n",
      "W             1296 non-null int64\n",
      "L             1296 non-null int64\n",
      "R             1296 non-null int64\n",
      "AB            1296 non-null int64\n",
      "H             1296 non-null int64\n",
      "2B            1296 non-null int64\n",
      "3B            1296 non-null int64\n",
      "HR            1296 non-null int64\n",
      "BB            1296 non-null float64\n",
      "SO            1296 non-null float64\n",
      "SB            1296 non-null float64\n",
      "CS            1296 non-null float64\n",
      "HBP           1296 non-null float64\n",
      "SF            1296 non-null float64\n",
      "RA            1296 non-null int64\n",
      "ER            1296 non-null int64\n",
      "ERA           1296 non-null float64\n",
      "CG            1296 non-null int64\n",
      "SHO           1296 non-null int64\n",
      "SV            1296 non-null int64\n",
      "IPouts        1296 non-null int64\n",
      "HA            1296 non-null int64\n",
      "HRA           1296 non-null int64\n",
      "BBA           1296 non-null int64\n",
      "SOA           1296 non-null int64\n",
      "E             1296 non-null int64\n",
      "DP            1296 non-null int64\n",
      "FP            1296 non-null float64\n",
      "attendance    1296 non-null float64\n",
      "BPF           1296 non-null int64\n",
      "PPF           1296 non-null int64\n",
      "Playoff       1296 non-null int64\n",
      "WHIP          1296 non-null float64\n",
      "KBB           1296 non-null float64\n",
      "KAB           1296 non-null float64\n",
      "Bavg          1296 non-null float64\n",
      "Slug          1296 non-null float64\n",
      "OBP           1296 non-null float64\n",
      "OPS           1296 non-null float64\n",
      "dtypes: float64(16), int64(26)\n",
      "memory usage: 435.4 KB\n",
      "Team 2017\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 1294 to 1323\n",
      "Data columns (total 42 columns):\n",
      "Unnamed: 0    30 non-null int64\n",
      "yearID        30 non-null int64\n",
      "Rank          30 non-null int64\n",
      "W             30 non-null int64\n",
      "L             30 non-null int64\n",
      "R             30 non-null int64\n",
      "AB            30 non-null int64\n",
      "H             30 non-null int64\n",
      "2B            30 non-null int64\n",
      "3B            30 non-null int64\n",
      "HR            30 non-null int64\n",
      "BB            30 non-null float64\n",
      "SO            30 non-null float64\n",
      "SB            30 non-null float64\n",
      "CS            30 non-null float64\n",
      "HBP           30 non-null float64\n",
      "SF            30 non-null float64\n",
      "RA            30 non-null int64\n",
      "ER            30 non-null int64\n",
      "ERA           30 non-null float64\n",
      "CG            30 non-null int64\n",
      "SHO           30 non-null int64\n",
      "SV            30 non-null int64\n",
      "IPouts        30 non-null int64\n",
      "HA            30 non-null int64\n",
      "HRA           30 non-null int64\n",
      "BBA           30 non-null int64\n",
      "SOA           30 non-null int64\n",
      "E             30 non-null int64\n",
      "DP            30 non-null int64\n",
      "FP            30 non-null float64\n",
      "attendance    30 non-null float64\n",
      "BPF           30 non-null int64\n",
      "PPF           30 non-null int64\n",
      "Playoff       30 non-null int64\n",
      "WHIP          30 non-null float64\n",
      "KBB           30 non-null float64\n",
      "KAB           30 non-null float64\n",
      "Bavg          30 non-null float64\n",
      "Slug          30 non-null float64\n",
      "OBP           30 non-null float64\n",
      "OPS           30 non-null float64\n",
      "dtypes: float64(16), int64(26)\n",
      "memory usage: 10.1 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "team = pd.read_csv('teams2Plus.csv')\n",
    "\n",
    "#Convert Y/N playoff flag to 1/0 indicator\n",
    "team['Playoff'] = team['Playoff'].map({'Y':1, 'N':0})\n",
    "\n",
    "#Drop records with missing values in the Playoff column\n",
    "team = team[np.isfinite(team['Playoff'])]\n",
    "team.Playoff = team.Playoff.astype(int)\n",
    "\n",
    "#Store all franchise IDs per row for future references\n",
    "allfranchID = team['franchID']\n",
    "\n",
    "#Drop Categorial Columns with no predictive ability\n",
    "team = team.drop(['teamIDBR', 'teamIDlahman45', 'teamIDretro', 'G', 'teamID', 'Ghome', 'name', 'park', 'lgID', 'divID', 'salary'], axis=1)\n",
    "\n",
    "#Drop Columns which introduce leakage\n",
    "team = team.drop(['LgWin', 'DivWin', 'WCWin', 'WSWin'], axis=1)\n",
    "\n",
    "#Create Cross Validation Object with 10 folds\n",
    "## Not necessary for this data set, but will code for practice\n",
    "cv = ShuffleSplit(n_splits = 10, test_size=0.80, random_state=0)\n",
    "\n",
    "#Also create Test set for 2017\n",
    "team2017 = team.loc[team['yearID'] == 2017]\n",
    "franchid2017 = team2017['franchID']\n",
    "\n",
    "\n",
    "#Drop last categorial column now that it has been preserved\n",
    "team = team.drop(['franchID'], axis=1)\n",
    "team2017 = team2017.drop(['franchID'], axis=1)\n",
    "\n",
    "#Create X Explanatory and Y response variables for regression\n",
    "teamY = team['Playoff']\n",
    "teamX = team.drop('Playoff', axis=1)\n",
    "\n",
    "print(\"Team DF\")\n",
    "team.info()\n",
    "team.tail()\n",
    "\n",
    "print(\"Team 2017\")\n",
    "team2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "yearID        0\n",
       "Rank          0\n",
       "W             0\n",
       "L             0\n",
       "R             0\n",
       "AB            0\n",
       "H             0\n",
       "2B            0\n",
       "3B            0\n",
       "HR            0\n",
       "BB            0\n",
       "SO            0\n",
       "SB            0\n",
       "CS            0\n",
       "HBP           0\n",
       "SF            0\n",
       "RA            0\n",
       "ER            0\n",
       "ERA           0\n",
       "CG            0\n",
       "SHO           0\n",
       "SV            0\n",
       "IPouts        0\n",
       "HA            0\n",
       "HRA           0\n",
       "BBA           0\n",
       "SOA           0\n",
       "E             0\n",
       "DP            0\n",
       "FP            0\n",
       "attendance    0\n",
       "BPF           0\n",
       "PPF           0\n",
       "Playoff       0\n",
       "WHIP          0\n",
       "KBB           0\n",
       "KAB           0\n",
       "Bavg          0\n",
       "Slug          0\n",
       "OBP           0\n",
       "OPS           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last check for NA values\n",
    "team.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresssion\n",
    "#### Grid Search CV\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit To:  https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateClassifierEstimator(classifierEstimator, X, y, cv):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, teamX, teamY, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "\n",
    "    return scoresResults\n",
    "\n",
    "def EvaluateClassifierEstimator2(classifierEstimator, X, y, cv):\n",
    "    \n",
    "    #Perform cross validation \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predictions = cross_val_predict(classifierEstimator, teamX, teamY, cv=cv)\n",
    "    \n",
    "    #model evaluation \n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    \n",
    "    #pass true test set values and predictions to classification_report\n",
    "    classReport = classification_report(Y,predictions)\n",
    "    confMat = confusion_matrix(Y,predictions)\n",
    "    acc = accuracy_score(Y,predictions)\n",
    "    \n",
    "    print (classReport)\n",
    "    print (confMat)\n",
    "    print (acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Logistic Regression Using Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.8, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'penalty': ['l2'], 'random_state': [0], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'max_iter': [100, 500], 'class_weight': ['balanced', 'none'], 'solver': ['lbfgs']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logisitic regression 10-fold cross-validation \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(teamX, teamY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.94248649e-04, -6.47705199e-05, -1.70403632e-03,\n",
       "         6.50218861e-03, -6.61468392e-03,  1.92541427e-02,\n",
       "        -6.30503860e-03,  6.77202773e-03, -9.10675933e-05,\n",
       "         1.33138918e-03,  6.30086572e-03,  1.22436629e-03,\n",
       "         2.71654751e-03,  3.78392302e-03,  5.56902667e-06,\n",
       "         1.75407168e-03,  1.41434989e-03, -1.24676218e-02,\n",
       "        -1.11756650e-02, -7.54723759e-05, -3.36355058e-04,\n",
       "         3.30589121e-04,  4.83258121e-03,  5.05353535e-03,\n",
       "         5.96123108e-04, -2.99727114e-03, -5.72835491e-03,\n",
       "        -1.04105601e-03, -8.14246079e-04,  2.91857071e-04,\n",
       "         9.89066714e-08,  7.64938294e-07, -1.25560193e-04,\n",
       "        -3.38681559e-04, -5.38167226e-06,  2.40880083e-05,\n",
       "         6.55015504e-07,  1.51165229e-06,  5.77495988e-06,\n",
       "         1.65180673e-06,  7.42676661e-06]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diplay the top model parameters\n",
    "regGridSearch.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.86557\n",
      "The average precision for all cv folds is: \t\t\t 0.68189\n",
      "The average recall for all cv folds is: \t\t\t 0.50894\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.870781</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.516304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.883317</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.647368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.866924</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.857281</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.422680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.863067</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.544041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.869817</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.621762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.862102</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.463918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.853423</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>0.465969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.874638</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.854388</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.484043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.870781   0.678571  0.516304\n",
       "1  0.883317   0.694915  0.647368\n",
       "2  0.866924   0.702479  0.454545\n",
       "3  0.857281   0.694915  0.422680\n",
       "4  0.863067   0.660377  0.544041\n",
       "5  0.869817   0.659341  0.621762\n",
       "6  0.862102   0.697674  0.463918\n",
       "7  0.853423   0.640288  0.465969\n",
       "8  0.874638   0.762712  0.468750\n",
       "9  0.854388   0.627586  0.484043"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the best parameters for our Linear Regression object\n",
    "classifierEst = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateClassifierEstimator(classifierEst, teamX, teamY, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.94248649e-04, -6.47705199e-05, -1.70403632e-03,\n",
       "         6.50218861e-03, -6.61468392e-03,  1.92541427e-02,\n",
       "        -6.30503860e-03,  6.77202773e-03, -9.10675933e-05,\n",
       "         1.33138918e-03,  6.30086572e-03,  1.22436629e-03,\n",
       "         2.71654751e-03,  3.78392302e-03,  5.56902667e-06,\n",
       "         1.75407168e-03,  1.41434989e-03, -1.24676218e-02,\n",
       "        -1.11756650e-02, -7.54723759e-05, -3.36355058e-04,\n",
       "         3.30589121e-04,  4.83258121e-03,  5.05353535e-03,\n",
       "         5.96123108e-04, -2.99727114e-03, -5.72835491e-03,\n",
       "        -1.04105601e-03, -8.14246079e-04,  2.91857071e-04,\n",
       "         9.89066714e-08,  7.64938294e-07, -1.25560193e-04,\n",
       "        -3.38681559e-04, -5.38167226e-06,  2.40880083e-05,\n",
       "         6.55015504e-07,  1.51165229e-06,  5.77495988e-06,\n",
       "         1.65180673e-06,  7.42676661e-06]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regGridSearch.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain GridSearch Prediction\n",
      "[0 1 0 ... 0 0 1]\n",
      "[[0.99412152 0.00587848]\n",
      " [0.0960525  0.9039475 ]\n",
      " [0.89725698 0.10274302]\n",
      " ...\n",
      " [0.95323381 0.04676619]\n",
      " [0.99234163 0.00765837]\n",
      " [0.35492726 0.64507274]]\n",
      "Best Estimator GridSearch Prediction\n",
      "[0 1 0 ... 0 0 1]\n",
      "[[0.99412152 0.00587848]\n",
      " [0.0960525  0.9039475 ]\n",
      " [0.89725698 0.10274302]\n",
      " ...\n",
      " [0.95323381 0.04676619]\n",
      " [0.99234163 0.00765837]\n",
      " [0.35492726 0.64507274]]\n"
     ]
    }
   ],
   "source": [
    "#Predictions using Grid Search CV\n",
    "print(\"Plain GridSearch Prediction\")\n",
    "print(regGridSearch.predict(teamX))\n",
    "print(regGridSearch.predict_proba(teamX))\n",
    "\n",
    "#Is there a difference between .predict and .best_estimator_.predict?  Nope.\n",
    "print(\"Best Estimator GridSearch Prediction\")\n",
    "print(regGridSearch.best_estimator_.predict(teamX))\n",
    "print(regGridSearch.best_estimator_.predict_proba(teamX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Scaled vs Unscaled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:    9.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=10, class_weight='none', dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "#Credit to:  Jake Drew NC Education Data Set Analysis\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "#### Added by GS ####\n",
    "print(\"Logistic Regression 1st Pass\")\n",
    "regEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(teamX, teamY)\n",
    "\n",
    "#Use the best parameters for our Linear Regression object\n",
    "classifierEst = regGridSearch.best_estimator_\n",
    "#### End Added by GS ####\n",
    "\n",
    "print(\"Logistic Regression Second Pass\")\n",
    "#Recursive Feature Elimination\n",
    "rfecv = RFECV(estimator=classifierEst, step=1, cv=cv, scoring='accuracy')\n",
    "X_BestFeatures = rfecv.fit_transform(teamX, teamY)\n",
    "\n",
    "#create a pipeline to scale all of the data and perform logistic regression during each grid search step.\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "#Define a range of hyper parameters for grid search\n",
    "parameters = { 'logisticregression__penalty':['l2']\n",
    "              ,'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'logisticregression__class_weight': ['balanced','none']\n",
    "              ,'logisticregression__random_state': [0]\n",
    "              ,'logisticregression__solver': ['lbfgs']\n",
    "              ,'logisticregression__max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(pipe, parameters, cv=cv, scoring='accuracy')\n",
    "\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "grid.fit(teamX, teamY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.98042\n",
      "The average precision for all cv folds is: \t\t\t 0.94962\n",
      "The average recall for all cv folds is: \t\t\t 0.94366\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972999</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.992285</td>\n",
       "      <td>0.978610</td>\n",
       "      <td>0.978610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.991321</td>\n",
       "      <td>0.979275</td>\n",
       "      <td>0.974227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.992285</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.968912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.982642</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.984456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.974928</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.927835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.945998</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.992285</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.968177</td>\n",
       "      <td>0.893401</td>\n",
       "      <td>0.936170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.972999   0.943182  0.902174\n",
       "1  0.991321   1.000000  0.952632\n",
       "2  0.992285   0.978610  0.978610\n",
       "3  0.991321   0.979275  0.974227\n",
       "4  0.992285   0.989418  0.968912\n",
       "5  0.982642   0.926829  0.984456\n",
       "6  0.974928   0.937500  0.927835\n",
       "7  0.945998   0.868852  0.832461\n",
       "8  0.992285   0.979167  0.979167\n",
       "9  0.968177   0.893401  0.936170"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the best parameters for our Linear Regression object\n",
    "classifierEst = grid.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateClassifierEstimator(classifierEst, teamX, teamY, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n",
      "[[1.00000000e+00 5.81096988e-11]\n",
      " [2.56733454e-02 9.74326655e-01]\n",
      " [9.99835518e-01 1.64482157e-04]\n",
      " ...\n",
      " [9.99999997e-01 3.37262781e-09]\n",
      " [9.99999986e-01 1.36970413e-08]\n",
      " [3.68681241e-02 9.63131876e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_.predict(teamX))\n",
    "print(grid.best_estimator_.predict_proba(teamX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Toward Data Science Approach\n",
    "https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Using R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9552469135802469\n",
      "precision: 0.9285714285714286\n",
      "[[1043   15]\n",
      " [  43  195]]\n"
     ]
    }
   ],
   "source": [
    "#SVM for consolidated team level baseball data created in Lab 1.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "teamX_scaled = scaler.fit_transform(teamX)\n",
    "\n",
    "#train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(teamX_scaled, teamY)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(teamX_scaled)\n",
    "\n",
    "acc = mt.accuracy_score(teamY,y_hat)\n",
    "conf = mt.confusion_matrix(teamY,y_hat)\n",
    "prec = mt.precision_score(teamY, y_hat)\n",
    "print('accuracy:', acc )\n",
    "print('precision:', prec)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 41)\n",
      "(416,)\n",
      "[217 199]\n"
     ]
    }
   ],
   "source": [
    "#look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# SVM based Prediction\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD\n",
    "\n",
    "#use some compact notation for creating a linear SVM classifier with stichastic descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "regularize_const = 0.1\n",
    "iterations = 5\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', n_iter=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "scl = StandardScaler()\n",
    "for train_idx, test_idx in cv.split(X,y):\n",
    "    svm_sgd.fit(scl.fit_transform(X[train_idx]),y[train_idx])\n",
    "    yhat = svm_sgd.predict(scl.transform(X[test_idx]))\n",
    "    \n",
    "    conf = mt.confusion_matrix(y[test_idx],yhat)\n",
    "    acc = mt.accuracy_score(y[test_idx],yhat)\n",
    "\n",
    "print('SVM:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
