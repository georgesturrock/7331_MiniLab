{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining - Mini Lab\n",
    "### Team 2 - Patricia Goresen, Jeffrey Lancon, Brychan Manry, George Sturrock\n",
    "#### June 17, 2018\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "#### Data Description\n",
    "The sujbect matter for this Lab assignment is team level data from the Lahman baseball database.  The database was described in detail during Lab 1.  The team summarized team level statistics generated in Lab 1 is used as the input data set for this study.  The team level data was summarized from approximately 30,000 rows of data from team level statistics dating back to 1970 and payroll data.  \n",
    "#### Objective\n",
    "The ultimate objective is to find the best model to predict if a team will make the Playoffs given the available statistical data.  To meet this objective, this section will examine three different models to determine which produce the best accuracy, recall and precision scores.  The three models are:  \n",
    "    - GridSearchCV Logistic Regression with manual variable reduction\n",
    "    - GridSearchCV Logistic Regression with recursive feature elimination\n",
    "    - Support Vector Machine\n",
    "#### Approach\n",
    "First, the input data set will have categorical features with little value (ball park name and disparate database identifiers) removed.  Features with near zero variance (such as games played) will also be removed.  Features which introduce leakage (such as Wins and how far a team progressed in the playoffs) will be removed as well.  The data will then be split into a explanatory (\"X\") and response (\"Y\") dataframes to feed into the different models.   \n",
    "\n",
    "The \"GridSearchCV Logistic Regression with manual feature reduction\" model will start begin remaining explanatory variables and use correlation scores, variable inflation factors and significance scores to manually reduce the number of features input into the regression function.\n",
    "\n",
    "The \"GridSearchCV Logistic Regression with recursive feature elimination\" and \"Support Vector Machine\" models will also have the remaining explanatory variables input into it's pipeline for analysis.  The team will allow the recursive feature elimination function and Support Vector Machine to determine which features to include in the end model on with no intervention.  \n",
    "\n",
    "Model accuracy, recall and precision will be used to determine which model yields the best results to predict whether or not a team will make the Major League Baseball Playoffs.  \n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1296 entries, 0 to 1323\n",
      "Data columns (total 36 columns):\n",
      "yearID    1296 non-null int64\n",
      "R         1296 non-null int64\n",
      "AB        1296 non-null int64\n",
      "H         1296 non-null int64\n",
      "2B        1296 non-null int64\n",
      "3B        1296 non-null int64\n",
      "HR        1296 non-null int64\n",
      "BB        1296 non-null float64\n",
      "SO        1296 non-null float64\n",
      "SB        1296 non-null float64\n",
      "CS        1296 non-null float64\n",
      "HBP       1296 non-null float64\n",
      "SF        1296 non-null float64\n",
      "RA        1296 non-null int64\n",
      "ER        1296 non-null int64\n",
      "ERA       1296 non-null float64\n",
      "CG        1296 non-null int64\n",
      "SHO       1296 non-null int64\n",
      "SV        1296 non-null int64\n",
      "IPouts    1296 non-null int64\n",
      "HA        1296 non-null int64\n",
      "HRA       1296 non-null int64\n",
      "BBA       1296 non-null int64\n",
      "SOA       1296 non-null int64\n",
      "E         1296 non-null int64\n",
      "DP        1296 non-null int64\n",
      "FP        1296 non-null float64\n",
      "BPF       1296 non-null int64\n",
      "PPF       1296 non-null int64\n",
      "WHIP      1296 non-null float64\n",
      "KBB       1296 non-null float64\n",
      "KAB       1296 non-null float64\n",
      "Bavg      1296 non-null float64\n",
      "Slug      1296 non-null float64\n",
      "OBP       1296 non-null float64\n",
      "OPS       1296 non-null float64\n",
      "dtypes: float64(15), int64(21)\n",
      "memory usage: 374.6 KB\n",
      "teamXRfecv None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1296 entries, 0 to 1323\n",
      "Data columns (total 36 columns):\n",
      "yearID    1296 non-null int64\n",
      "R         1296 non-null int64\n",
      "AB        1296 non-null int64\n",
      "H         1296 non-null int64\n",
      "2B        1296 non-null int64\n",
      "3B        1296 non-null int64\n",
      "HR        1296 non-null int64\n",
      "BB        1296 non-null float64\n",
      "SO        1296 non-null float64\n",
      "SB        1296 non-null float64\n",
      "CS        1296 non-null float64\n",
      "HBP       1296 non-null float64\n",
      "SF        1296 non-null float64\n",
      "RA        1296 non-null int64\n",
      "ER        1296 non-null int64\n",
      "ERA       1296 non-null float64\n",
      "CG        1296 non-null int64\n",
      "SHO       1296 non-null int64\n",
      "SV        1296 non-null int64\n",
      "IPouts    1296 non-null int64\n",
      "HA        1296 non-null int64\n",
      "HRA       1296 non-null int64\n",
      "BBA       1296 non-null int64\n",
      "SOA       1296 non-null int64\n",
      "E         1296 non-null int64\n",
      "DP        1296 non-null int64\n",
      "FP        1296 non-null float64\n",
      "BPF       1296 non-null int64\n",
      "PPF       1296 non-null int64\n",
      "WHIP      1296 non-null float64\n",
      "KBB       1296 non-null float64\n",
      "KAB       1296 non-null float64\n",
      "Bavg      1296 non-null float64\n",
      "Slug      1296 non-null float64\n",
      "OBP       1296 non-null float64\n",
      "OPS       1296 non-null float64\n",
      "dtypes: float64(15), int64(21)\n",
      "memory usage: 374.6 KB\n",
      "teamXSVM None\n",
      "Team DF\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1296 entries, 0 to 1323\n",
      "Data columns (total 37 columns):\n",
      "Unnamed: 0    1296 non-null int64\n",
      "yearID        1296 non-null int64\n",
      "R             1296 non-null int64\n",
      "AB            1296 non-null int64\n",
      "H             1296 non-null int64\n",
      "2B            1296 non-null int64\n",
      "3B            1296 non-null int64\n",
      "HR            1296 non-null int64\n",
      "BB            1296 non-null float64\n",
      "SO            1296 non-null float64\n",
      "SB            1296 non-null float64\n",
      "CS            1296 non-null float64\n",
      "HBP           1296 non-null float64\n",
      "SF            1296 non-null float64\n",
      "RA            1296 non-null int64\n",
      "ER            1296 non-null int64\n",
      "ERA           1296 non-null float64\n",
      "CG            1296 non-null int64\n",
      "SHO           1296 non-null int64\n",
      "SV            1296 non-null int64\n",
      "IPouts        1296 non-null int64\n",
      "HA            1296 non-null int64\n",
      "HRA           1296 non-null int64\n",
      "BBA           1296 non-null int64\n",
      "SOA           1296 non-null int64\n",
      "E             1296 non-null int64\n",
      "DP            1296 non-null int64\n",
      "FP            1296 non-null float64\n",
      "BPF           1296 non-null int64\n",
      "PPF           1296 non-null int64\n",
      "WHIP          1296 non-null float64\n",
      "KBB           1296 non-null float64\n",
      "KAB           1296 non-null float64\n",
      "Bavg          1296 non-null float64\n",
      "Slug          1296 non-null float64\n",
      "OBP           1296 non-null float64\n",
      "OPS           1296 non-null float64\n",
      "dtypes: float64(15), int64(22)\n",
      "memory usage: 384.8 KB\n",
      "Team 2017\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 1294 to 1323\n",
      "Data columns (total 37 columns):\n",
      "Unnamed: 0    30 non-null int64\n",
      "yearID        30 non-null int64\n",
      "R             30 non-null int64\n",
      "AB            30 non-null int64\n",
      "H             30 non-null int64\n",
      "2B            30 non-null int64\n",
      "3B            30 non-null int64\n",
      "HR            30 non-null int64\n",
      "BB            30 non-null float64\n",
      "SO            30 non-null float64\n",
      "SB            30 non-null float64\n",
      "CS            30 non-null float64\n",
      "HBP           30 non-null float64\n",
      "SF            30 non-null float64\n",
      "RA            30 non-null int64\n",
      "ER            30 non-null int64\n",
      "ERA           30 non-null float64\n",
      "CG            30 non-null int64\n",
      "SHO           30 non-null int64\n",
      "SV            30 non-null int64\n",
      "IPouts        30 non-null int64\n",
      "HA            30 non-null int64\n",
      "HRA           30 non-null int64\n",
      "BBA           30 non-null int64\n",
      "SOA           30 non-null int64\n",
      "E             30 non-null int64\n",
      "DP            30 non-null int64\n",
      "FP            30 non-null float64\n",
      "BPF           30 non-null int64\n",
      "PPF           30 non-null int64\n",
      "WHIP          30 non-null float64\n",
      "KBB           30 non-null float64\n",
      "KAB           30 non-null float64\n",
      "Bavg          30 non-null float64\n",
      "Slug          30 non-null float64\n",
      "OBP           30 non-null float64\n",
      "OPS           30 non-null float64\n",
      "dtypes: float64(15), int64(22)\n",
      "memory usage: 8.9 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "team = pd.read_csv('~/7331_MiniLab/data/teams2Plus.csv')\n",
    "\n",
    "#Convert Y/N playoff flag to 1/0 indicator\n",
    "team['Playoff'] = team['Playoff'].map({'Y':1, 'N':0})\n",
    "\n",
    "#Drop records with missing values in the Playoff column\n",
    "team = team[np.isfinite(team['Playoff'])]\n",
    "team.Playoff = team.Playoff.astype(int)\n",
    "\n",
    "#Store all franchise IDs per row for future references\n",
    "allfranchID = team['franchID']\n",
    "\n",
    "#Create Y Response Variable DF\n",
    "teamY = team['Playoff']\n",
    "\n",
    "#Drop Categorial Columns with no predictive ability\n",
    "team = team.drop(['teamIDBR', 'teamIDlahman45', 'teamIDretro', 'G', 'teamID', 'Ghome', 'name', 'park', 'lgID', 'divID', 'salary', 'attendance', 'Playoff'], axis=1)\n",
    "\n",
    "#Drop Columns which introduce leakage\n",
    "team = team.drop(['LgWin', 'DivWin', 'WCWin', 'WSWin', 'W', 'L', 'Rank'], axis=1)\n",
    "\n",
    "#Create Cross Validation Object with 10 folds with 80/20 train - test split\n",
    "cv = ShuffleSplit(n_splits = 10, test_size=0.20, random_state=0)\n",
    "\n",
    "#Also create Test set for 2017\n",
    "team2017 = team.loc[team['yearID'] == 2017]\n",
    "franchid2017 = team2017['franchID']\n",
    "\n",
    "#Drop last categorial column now that it has been preserved\n",
    "team = team.drop(['franchID'], axis=1)\n",
    "team2017 = team2017.drop(['franchID'], axis=1)\n",
    "\n",
    "#Create X Explanatory Variables DF to support the individual models\n",
    "teamX = team\n",
    "teamXRfecv = team\n",
    "teamXSVM = team\n",
    "teamXRfecv = teamXRfecv.drop(['Unnamed: 0'], axis=1)\n",
    "teamXSVM = teamXSVM.drop(['Unnamed: 0'], axis=1)\n",
    "print(\"teamXRfecv\", teamXRfecv.info())\n",
    "print(\"teamXSVM\", teamXSVM.info())\n",
    "\n",
    "print(\"Team DF\")\n",
    "team.info()\n",
    "#teamX_colNames = list(teamX)\n",
    "\n",
    "print(\"Team 2017\")\n",
    "team2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "yearID        0\n",
       "R             0\n",
       "AB            0\n",
       "H             0\n",
       "2B            0\n",
       "3B            0\n",
       "HR            0\n",
       "BB            0\n",
       "SO            0\n",
       "SB            0\n",
       "CS            0\n",
       "HBP           0\n",
       "SF            0\n",
       "RA            0\n",
       "ER            0\n",
       "ERA           0\n",
       "CG            0\n",
       "SHO           0\n",
       "SV            0\n",
       "IPouts        0\n",
       "HA            0\n",
       "HRA           0\n",
       "BBA           0\n",
       "SOA           0\n",
       "E             0\n",
       "DP            0\n",
       "FP            0\n",
       "BPF           0\n",
       "PPF           0\n",
       "WHIP          0\n",
       "KBB           0\n",
       "KAB           0\n",
       "Bavg          0\n",
       "Slug          0\n",
       "OBP           0\n",
       "OPS           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last check for NA values\n",
    "team.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colinearity\n",
    "As determined in Lab 1, colinearity is an issue in this data set.  Highly correlated and redundant features will be removed from the input into the \"GridSearchCV Logistic Regression with manual variable reduction\" model.  Though colinearity is a objective measurement, some subjective descretion will be exercised when removing features.  \n",
    "\n",
    "##### Starting Colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP          E            -0.958084\n",
      "CG          yearID       -0.828620\n",
      "            Unnamed: 0   -0.820053\n",
      "SHO         ERA          -0.669942\n",
      "WHIP        SHO          -0.651043\n",
      "                            ...   \n",
      "KAB         SO            0.973806\n",
      "OPS         Slug          0.974699\n",
      "BPF         PPF           0.978014\n",
      "RA          ER            0.985641\n",
      "Unnamed: 0  yearID        0.999068\n",
      "Length: 666, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Create correlation matrix\n",
    "teamCorrMat = team.corr()\n",
    "\n",
    "# Highest Correlation Pairs\n",
    "corrPairs = teamCorrMat.unstack().sort_values(kind=\"quicksort\")\n",
    "#- REMOVE DUPLICATES\n",
    "corrPairs = corrPairs[::2]\n",
    "corrPairs = corrPairs[corrPairs.index.get_level_values(0) != corrPairs.index.get_level_values(1)]\n",
    "with pd.option_context('display.max_rows',10):\n",
    "    print(corrPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ending Colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SV   CG    -0.521343\n",
      "HRA  CG    -0.517123\n",
      "KBB  CG    -0.450180\n",
      "CG   RA    -0.330862\n",
      "R    CG    -0.233253\n",
      "              ...   \n",
      "AB   RA     0.494169\n",
      "HRA  R      0.524398\n",
      "R    AB     0.578170\n",
      "RA   HRA    0.743288\n",
      "OBP  R      0.814649\n",
      "Length: 28, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Drop highly correlated, insignificant and high VIF columns.\n",
    "teamX = team.drop(['CS', 'BB', 'SB', '2B', '3B', 'BBA', 'DP', 'HR', 'yearID', 'WHIP', 'HA', 'HBP', 'Slug', 'SF', 'OPS', 'Bavg', 'SOA', 'KAB', 'SHO', 'FP', 'E', 'ER', 'IPouts', 'SO', 'BPF', 'PPF', 'Unnamed: 0', 'ERA', 'H'], axis=1)\n",
    "\n",
    "#Create correlation matrix\n",
    "teamCorrMat = teamX.corr()\n",
    "\n",
    "# Highest Correlation Pairs\n",
    "corrPairs = teamCorrMat.unstack().sort_values(kind=\"quicksort\")\n",
    "#- REMOVE DUPLICATES\n",
    "corrPairs = corrPairs[::2]\n",
    "corrPairs = corrPairs[corrPairs.index.get_level_values(0) != corrPairs.index.get_level_values(1)]\n",
    "with pd.option_context('display.max_rows',10):\n",
    "    print(corrPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data\n",
    "It is critical to scale this data set for input into each of the three models in this report.  Several features in the data set are decimal measurements that will never exceed 1.  The realistic range of Batting Average is approximately 0.21 to 0.3.  Other features such as attendence could range from tens of thousands to hundreds of thousands.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scale data\n",
    "scaler = StandardScaler()\n",
    "teamX_scaled = scaler.fit_transform(teamX)\n",
    "teamXRfecv_scaled = scaler.fit_transform(teamXRfecv)\n",
    "teamXSVM_scaled = scaler.fit_transform(teamXSVM)\n",
    "\n",
    "#Save as data frames\n",
    "df_teamX_scaled = pd.DataFrame(teamX_scaled)\n",
    "df_teamXRfecv_scaled = pd.DataFrame(teamXRfecv_scaled)\n",
    "df_teamXSVM_scaled = pd.DataFrame(teamXSVM_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Inflation Factors (VIF)\n",
    "VIF will also be addressed prior to running the \"GridSearchCV Logistic Regression with manual variable reduction\" model.  The starting VIF of the unscaled team data shows several features with high VIF Factors.\n",
    "##### Beginning VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.077363e+03</td>\n",
       "      <td>Unnamed: 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.433994e+06</td>\n",
       "      <td>yearID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.211189e+03</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.266656e+05</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.297657e+05</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.792292e+03</td>\n",
       "      <td>2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.276009e+02</td>\n",
       "      <td>3B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.407856e+04</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.019001e+04</td>\n",
       "      <td>BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.838337e+04</td>\n",
       "      <td>SO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.874866e+01</td>\n",
       "      <td>SB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.059104e+01</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.689668e+02</td>\n",
       "      <td>HBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.277409e+01</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.223108e+03</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.784064e+05</td>\n",
       "      <td>ER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.715971e+05</td>\n",
       "      <td>ERA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.343285e+01</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.402664e+01</td>\n",
       "      <td>SHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.906925e+01</td>\n",
       "      <td>SV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.075035e+05</td>\n",
       "      <td>IPouts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.782902e+05</td>\n",
       "      <td>HA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.030460e+02</td>\n",
       "      <td>HRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.921630e+04</td>\n",
       "      <td>BBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.184049e+03</td>\n",
       "      <td>SOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.862108e+03</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.137754e+02</td>\n",
       "      <td>DP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.891762e+06</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.450697e+04</td>\n",
       "      <td>BPF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.412464e+04</td>\n",
       "      <td>PPF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.135300e+05</td>\n",
       "      <td>WHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9.488985e+02</td>\n",
       "      <td>KBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.803589e+04</td>\n",
       "      <td>KAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.173560e+05</td>\n",
       "      <td>Bavg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>inf</td>\n",
       "      <td>Slug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>inf</td>\n",
       "      <td>OBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>inf</td>\n",
       "      <td>OPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VIF Factor    features\n",
       "0   1.077363e+03  Unnamed: 0\n",
       "1   5.433994e+06      yearID\n",
       "2   1.211189e+03           R\n",
       "3   3.266656e+05          AB\n",
       "4   2.297657e+05           H\n",
       "5   4.792292e+03          2B\n",
       "6   3.276009e+02          3B\n",
       "7   1.407856e+04          HR\n",
       "8   2.019001e+04          BB\n",
       "9   3.838337e+04          SO\n",
       "10  1.874866e+01          SB\n",
       "11  3.059104e+01          CS\n",
       "12  1.689668e+02         HBP\n",
       "13  8.277409e+01          SF\n",
       "14  6.223108e+03          RA\n",
       "15  1.784064e+05          ER\n",
       "16  1.715971e+05         ERA\n",
       "17  1.343285e+01          CG\n",
       "18  1.402664e+01         SHO\n",
       "19  4.906925e+01          SV\n",
       "20  2.075035e+05      IPouts\n",
       "21  2.782902e+05          HA\n",
       "22  1.030460e+02         HRA\n",
       "23  3.921630e+04         BBA\n",
       "24  1.184049e+03         SOA\n",
       "25  1.862108e+03           E\n",
       "26  1.137754e+02          DP\n",
       "27  4.891762e+06          FP\n",
       "28  2.450697e+04         BPF\n",
       "29  2.412464e+04         PPF\n",
       "30  5.135300e+05        WHIP\n",
       "31  9.488985e+02         KBB\n",
       "32  3.803589e+04         KAB\n",
       "33  7.173560e+05        Bavg\n",
       "34           inf        Slug\n",
       "35           inf         OBP\n",
       "36           inf         OPS"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "df2_vif = pd.DataFrame()\n",
    "df2_vif[\"VIF Factor\"] = [vif(team.values, i) for i in range(team.shape[1])]\n",
    "#df2_vif[\"features\"] = df_teamX_scaled.columns\n",
    "df2_vif[\"features\"] = team.columns\n",
    "df2_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ending VIF\n",
    "After applying a threshold of 10, the VIF for data input into the manual Logistic Regression model has been reduced significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.395007</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.138265</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.591007</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.977814</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.184272</td>\n",
       "      <td>SV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.826117</td>\n",
       "      <td>HRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.447916</td>\n",
       "      <td>KBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.039360</td>\n",
       "      <td>OBP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF Factor features\n",
       "0    8.395007        R\n",
       "1    3.138265       AB\n",
       "2    5.591007       RA\n",
       "3    2.977814       CG\n",
       "4    2.184272       SV\n",
       "5    3.826117      HRA\n",
       "6    2.447916      KBB\n",
       "7    5.039360      OBP"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Credit to:\n",
    "###https://stats.stackexchange.com/questions/155028/how-to-systematically-remove-collinear-variables-in-python\n",
    "###https://etav.github.io/python/vif_factor_python.html\n",
    "\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "df2_vif = pd.DataFrame()\n",
    "df2_vif[\"VIF Factor\"] = [vif(df_teamX_scaled.values, i) for i in range(df_teamX_scaled.shape[1])]\n",
    "#df2_vif[\"features\"] = df_teamX_scaled.columns\n",
    "df2_vif[\"features\"] = teamX.columns\n",
    "df2_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Feature Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.245847\n",
      "         Iterations 8\n",
      "                        Results: Logit\n",
      "===============================================================\n",
      "Model:              Logit            No. Iterations:   8.0000  \n",
      "Dependent Variable: Playoff          Pseudo R-squared: 0.484   \n",
      "Date:               2018-06-17 17:48 AIC:              653.2342\n",
      "No. Observations:   1296             BIC:              694.5705\n",
      "Df Model:           7                Log-Likelihood:   -318.62 \n",
      "Df Residuals:       1288             LL-Null:          -618.03 \n",
      "Converged:          1.0000           Scale:            1.0000  \n",
      "-----------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z      P>|z|     [0.025    0.975]\n",
      "-----------------------------------------------------------------\n",
      "R        0.0274     0.0022   12.5624   0.0000    0.0231    0.0317\n",
      "AB      -0.0027     0.0005   -5.7628   0.0000   -0.0036   -0.0018\n",
      "RA      -0.0202     0.0027   -7.4099   0.0000   -0.0255   -0.0148\n",
      "CG       0.0340     0.0110    3.0870   0.0020    0.0124    0.0556\n",
      "SV       0.1128     0.0169    6.6873   0.0000    0.0797    0.1458\n",
      "HRA     -0.0145     0.0058   -2.4878   0.0129   -0.0260   -0.0031\n",
      "KBB      1.0381     0.3281    3.1643   0.0016    0.3951    1.6810\n",
      "OBP      3.7713     4.4626    0.8451   0.3981   -4.9753   12.5179\n",
      "===============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Summary table with full model fit prior to scaling, cross validation or recursive \n",
    "#feature elimination.\n",
    "#Cursory check to verify feature significance\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model = sm.Logit(teamY, teamX)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit To:  https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "results = []\n",
    "\n",
    "def EvaluateClassifierEstimator(classifierEstimator, X, y, cv, model):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, teamX, teamY, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "    \n",
    "    results.append({'Model': model, 'Accuracy': Accavg, 'Precision': Preavg, 'Recall': Recavg})\n",
    "\n",
    "    return scoresResults\n",
    "\n",
    "def EvaluateClassifierEstimator2(classifierEstimator, X, y, cv):\n",
    "    \n",
    "    #Perform cross validation \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predictions = cross_val_predict(classifierEstimator, teamX, teamY, cv=cv)\n",
    "    \n",
    "    #model evaluation \n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    \n",
    "    #pass true test set values and predictions to classification_report\n",
    "    classReport = classification_report(Y,predictions)\n",
    "    confMat = confusion_matrix(Y,predictions)\n",
    "    acc = accuracy_score(Y,predictions)\n",
    "    \n",
    "    print (classReport)\n",
    "    print (confMat)\n",
    "    print (acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV Logistic Regression with Manual Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.2, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'class_weight': ['balanced', 'none'], 'random_state': [0], 'solver': ['lbfgs'], 'max_iter': [100, 500], 'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logisitic regression 10-fold cross-validation \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "#regGridSearch.fit(teamX, teamY)\n",
    "regGridSearch.fit(df_teamX_scaled, teamY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.60519102, -0.76252932, -1.97336804,  0.53512682,  1.0217957 ,\n",
       "        -0.51143328,  0.46728398,  0.06831141]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diplay the top model parameters\n",
    "regGridSearch.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.89385\n",
      "The average precision for all cv folds is: \t\t\t 0.76719\n",
      "The average recall for all cv folds is: \t\t\t 0.61226\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.679245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.673077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.508772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.884615   0.700000  0.608696\n",
       "1  0.888462   0.757576  0.543478\n",
       "2  0.903846   0.818182  0.679245\n",
       "3  0.884615   0.760000  0.678571\n",
       "4  0.907692   0.833333  0.673077\n",
       "5  0.900000   0.777778  0.608696\n",
       "6  0.853846   0.743590  0.508772\n",
       "7  0.896154   0.750000  0.558140\n",
       "8  0.900000   0.789474  0.625000\n",
       "9  0.919231   0.741935  0.638889"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the best parameters for our Linear Regression object\n",
    "classifierEst = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateClassifierEstimator(classifierEst, df_teamX_scaled, teamY, cv, \"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator GridSearch Prediction\n",
      "[0 1 0 ... 0 0 1]\n",
      "[[0.994294   0.005706  ]\n",
      " [0.08913697 0.91086303]\n",
      " [0.66284756 0.33715244]\n",
      " ...\n",
      " [0.99568585 0.00431415]\n",
      " [0.99548092 0.00451908]\n",
      " [0.26457073 0.73542927]]\n"
     ]
    }
   ],
   "source": [
    "#Predictions using Grid Search CV\n",
    "#print(\"Plain GridSearch Prediction\")\n",
    "#print(regGridSearch.predict(teamX))\n",
    "#print(regGridSearch.predict_proba(teamX))\n",
    "#print(regGridSearch.predict(df_teamX_scaled))\n",
    "#print(regGridSearch.predict_proba(df_teamX_scaled))\n",
    "\n",
    "#Is there a difference between .predict and .best_estimator_.predict?  Nope.\n",
    "print(\"Best Estimator GridSearch Prediction\")\n",
    "#print(regGridSearch.best_estimator_.predict(teamX))\n",
    "#print(regGridSearch.best_estimator_.predict_proba(teamX))\n",
    "print(regGridSearch.best_estimator_.predict(df_teamX_scaled))\n",
    "print(regGridSearch.best_estimator_.predict_proba(df_teamX_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV Logistic Regression with Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV Logistic Regression 1st Pass\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 265 out of 280 | elapsed:   10.3s remaining:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Ranking [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Support [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n",
      "Number of Features: 35\n",
      "Logistic Regression Second Pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.2, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__solver': ['lbfgs'], 'logisticregression__random_state': [0], 'logisticregression__penalty': ['l2'], 'logisticregression__class_weight': ['balanced', 'none'], 'logisticregression__max_iter': [100, 500], 'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Credit to:  Jake Drew NC Education Data Set Analysis\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "print(\"RFECV Logistic Regression 1st Pass\")\n",
    "rfecvEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfecvGridSearch = GridSearchCV(estimator=rfecvEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data using RFECV\n",
    "rfecvGridSearch.fit(df_teamXRfecv_scaled, teamY)\n",
    "\n",
    "#Use the best parameters for our RFECV Linear Regression object\n",
    "rfecvClassifierEst = rfecvGridSearch.best_estimator_\n",
    "\n",
    "#Recursive Feature Elimination\n",
    "rfecv = RFECV(estimator=rfecvClassifierEst, step=1, cv=cv, scoring='accuracy', verbose=1)\n",
    "#X_BestFeatures = rfecv.fit_transform(teamX, teamY)\n",
    "X_BestFeatures = rfecv.fit_transform(df_teamXRfecv_scaled, teamY)\n",
    "\n",
    "#Print RFECV Details\n",
    "print(\"Ranking\", rfecv.ranking_)\n",
    "print(\"Support\", rfecv.support_)\n",
    "print(\"Number of Features:\", rfecv.n_features_)\n",
    "\n",
    "print(\"Logistic Regression Second Pass\")\n",
    "#create a pipeline to scale all of the data and perform logistic regression during each grid search step.\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "#Define a range of hyper parameters for grid search\n",
    "parameters = { 'logisticregression__penalty':['l2']\n",
    "              ,'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'logisticregression__class_weight': ['balanced','none']\n",
    "              ,'logisticregression__random_state': [0]\n",
    "              ,'logisticregression__solver': ['lbfgs']\n",
    "              ,'logisticregression__max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(pipe, parameters, cv=cv, scoring='accuracy')\n",
    "\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "grid.fit(df_teamXRfecv_scaled, teamY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.88846\n",
      "The average precision for all cv folds is: \t\t\t 0.75864\n",
      "The average recall for all cv folds is: \t\t\t 0.58567\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.641509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.508772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.892308   0.736842  0.608696\n",
       "1  0.888462   0.757576  0.543478\n",
       "2  0.884615   0.755556  0.641509\n",
       "3  0.865385   0.723404  0.607143\n",
       "4  0.900000   0.842105  0.615385\n",
       "5  0.896154   0.787879  0.565217\n",
       "6  0.853846   0.743590  0.508772\n",
       "7  0.896154   0.750000  0.558140\n",
       "8  0.900000   0.789474  0.625000\n",
       "9  0.907692   0.700000  0.583333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the best parameters from RFECV for our Linear Regression object\n",
    "#rfecvClassifierEst = grid.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "#EvaluateClassifierEstimator(classifierEst, teamX, teamY, cv)\n",
    "EvaluateClassifierEstimator(rfecvClassifierEst, df_teamXRfecv_scaled, teamY, cv, 'Rfecv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n",
      "[[0.99643346 0.00356654]\n",
      " [0.07125492 0.92874508]\n",
      " [0.80909222 0.19090778]\n",
      " ...\n",
      " [0.9950237  0.0049763 ]\n",
      " [0.99603725 0.00396275]\n",
      " [0.31209965 0.68790035]]\n"
     ]
    }
   ],
   "source": [
    "#print(grid.best_estimator_.predict(teamX))\n",
    "#print(grid.best_estimator_.predict_proba(teamX))\n",
    "print(grid.best_estimator_.predict(df_teamXRfecv_scaled))\n",
    "print(grid.best_estimator_.predict_proba(df_teamXRfecv_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8865740740740741\n",
      "precision: 0.837037037037037\n",
      "recall: 0.47478991596638653\n",
      "[[1036   22]\n",
      " [ 125  113]]\n"
     ]
    }
   ],
   "source": [
    "#SVM for consolidated team level baseball data created in Lab 1.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#teamX_scaled = scaler.fit_transform(teamX)\n",
    "\n",
    "#train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(df_teamXSVM_scaled, teamY)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(df_teamXSVM_scaled)\n",
    "\n",
    "acc = mt.accuracy_score(teamY,y_hat)\n",
    "conf = mt.confusion_matrix(teamY,y_hat)\n",
    "prec = mt.precision_score(teamY, y_hat)\n",
    "recall = mt.recall_score(teamY, y_hat)\n",
    "print('accuracy:', acc )\n",
    "print('precision:', prec)\n",
    "print('recall:', recall)\n",
    "print(conf)\n",
    "\n",
    "results.append({'Model': 'SVM', 'Accuracy': acc, 'Precision': prec, 'Recall': recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484, 36)\n",
      "(484,)\n",
      "[257 227]\n"
     ]
    }
   ],
   "source": [
    "#look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# SVM based Prediction\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Summary\n",
    "All three planned models were sucessfully implemented as planned.  All models utilized cross validation to control results.  Stochastic Gradient Descent was not utilized for the support vector machine model as the size of the data set did not warrant it use.  Good results were achieved by all models.  The \"GridSearchCV Logistic Regression with manual variable reduction\" model ultimately produced the best accuracy and overall results.  The results are summarized in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manual</td>\n",
       "      <td>0.893846</td>\n",
       "      <td>0.767187</td>\n",
       "      <td>0.612256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rfecv</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.758643</td>\n",
       "      <td>0.585667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.474790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  Precision    Recall\n",
       "0  manual  0.893846   0.767187  0.612256\n",
       "1   Rfecv  0.888462   0.758643  0.585667\n",
       "2     SVM  0.886574   0.837037  0.474790"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results[['Model', 'Accuracy', 'Precision', 'Recall']]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Advantages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key References\n",
    "\n",
    "https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb\n",
    "https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb (Logit)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
