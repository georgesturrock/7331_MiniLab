{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining - Mini Lab\n",
    "### Team 2 - Patricia Goresen, Jeffrey Lancon, Brychan Manry, George Sturrock\n",
    "#### June 17, 2018\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "#### Data Description\n",
    "The sujbect matter for this Lab assignment is team level data from the Lahman baseball database.  The database was described in detail during Lab 1.  The team summarized team level statistics generated in Lab 1 is used as the input data set for this study.  The team level data was summarized from approximately 30,000 rows of data from team level statistics dating back to 1970 and payroll data.  \n",
    "#### Objective\n",
    "The ultimate objective is to find the best model to predict if a team will make the Playoffs given the available statistical data.  To meet this objective, this section will examine three different models to determine which produce the best accuracy, recall and precision scores.  The three models are:  \n",
    "    - GridSearchCV Logistic Regression with manual variable reduction\n",
    "    - GridSearchCV Logistic Regression with recursive feature elimination\n",
    "    - Support Vector Machine\n",
    "#### Approach\n",
    "First, the input data set will have categorical features with little value (ball park name and disparate database identifiers) removed.  Features with near zero variance (such as games played) will also be removed.  Features which introduce leakage (such as Wins and how far a team progressed in the playoffs) will be removed as well.  The data will then be split into a explanatory (\"X\") and response (\"Y\") dataframes to feed into the different models.   \n",
    "\n",
    "The \"GridSearchCV Logistic Regression with manual feature reduction\" model will start begin remaining explanatory variables and use correlation scores, variable inflation factors and significance scores to manually reduce the number of features input into the regression function.\n",
    "\n",
    "The \"GridSearchCV Logistic Regression with recursive feature elimination\" and \"Support Vector Machine\" models will also have the remaining explanatory variables input into it's pipeline for analysis.  The team will allow the recursive feature elimination function and Support Vector Machine to determine which features to include in the end model on with no intervention.  \n",
    "\n",
    "Model accuracy, recall and precision will be used to determine which model yields the best results to predict whether or not a team will make the Major League Baseball Playoffs.  \n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1296 entries, 0 to 1323\n",
      "Data columns (total 36 columns):\n",
      "yearID    1296 non-null int64\n",
      "R         1296 non-null int64\n",
      "AB        1296 non-null int64\n",
      "H         1296 non-null int64\n",
      "2B        1296 non-null int64\n",
      "3B        1296 non-null int64\n",
      "HR        1296 non-null int64\n",
      "BB        1296 non-null float64\n",
      "SO        1296 non-null float64\n",
      "SB        1296 non-null float64\n",
      "CS        1296 non-null float64\n",
      "HBP       1296 non-null float64\n",
      "SF        1296 non-null float64\n",
      "RA        1296 non-null int64\n",
      "ER        1296 non-null int64\n",
      "ERA       1296 non-null float64\n",
      "CG        1296 non-null int64\n",
      "SHO       1296 non-null int64\n",
      "SV        1296 non-null int64\n",
      "IPouts    1296 non-null int64\n",
      "HA        1296 non-null int64\n",
      "HRA       1296 non-null int64\n",
      "BBA       1296 non-null int64\n",
      "SOA       1296 non-null int64\n",
      "E         1296 non-null int64\n",
      "DP        1296 non-null int64\n",
      "FP        1296 non-null float64\n",
      "BPF       1296 non-null int64\n",
      "PPF       1296 non-null int64\n",
      "WHIP      1296 non-null float64\n",
      "KBB       1296 non-null float64\n",
      "KAB       1296 non-null float64\n",
      "Bavg      1296 non-null float64\n",
      "Slug      1296 non-null float64\n",
      "OBP       1296 non-null float64\n",
      "OPS       1296 non-null float64\n",
      "dtypes: float64(15), int64(21)\n",
      "memory usage: 374.6 KB\n",
      "teamXRfecv None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1296 entries, 0 to 1323\n",
      "Data columns (total 36 columns):\n",
      "yearID    1296 non-null int64\n",
      "R         1296 non-null int64\n",
      "AB        1296 non-null int64\n",
      "H         1296 non-null int64\n",
      "2B        1296 non-null int64\n",
      "3B        1296 non-null int64\n",
      "HR        1296 non-null int64\n",
      "BB        1296 non-null float64\n",
      "SO        1296 non-null float64\n",
      "SB        1296 non-null float64\n",
      "CS        1296 non-null float64\n",
      "HBP       1296 non-null float64\n",
      "SF        1296 non-null float64\n",
      "RA        1296 non-null int64\n",
      "ER        1296 non-null int64\n",
      "ERA       1296 non-null float64\n",
      "CG        1296 non-null int64\n",
      "SHO       1296 non-null int64\n",
      "SV        1296 non-null int64\n",
      "IPouts    1296 non-null int64\n",
      "HA        1296 non-null int64\n",
      "HRA       1296 non-null int64\n",
      "BBA       1296 non-null int64\n",
      "SOA       1296 non-null int64\n",
      "E         1296 non-null int64\n",
      "DP        1296 non-null int64\n",
      "FP        1296 non-null float64\n",
      "BPF       1296 non-null int64\n",
      "PPF       1296 non-null int64\n",
      "WHIP      1296 non-null float64\n",
      "KBB       1296 non-null float64\n",
      "KAB       1296 non-null float64\n",
      "Bavg      1296 non-null float64\n",
      "Slug      1296 non-null float64\n",
      "OBP       1296 non-null float64\n",
      "OPS       1296 non-null float64\n",
      "dtypes: float64(15), int64(21)\n",
      "memory usage: 374.6 KB\n",
      "teamXSVM None\n",
      "Team DF\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1296 entries, 0 to 1323\n",
      "Data columns (total 37 columns):\n",
      "Unnamed: 0    1296 non-null int64\n",
      "yearID        1296 non-null int64\n",
      "R             1296 non-null int64\n",
      "AB            1296 non-null int64\n",
      "H             1296 non-null int64\n",
      "2B            1296 non-null int64\n",
      "3B            1296 non-null int64\n",
      "HR            1296 non-null int64\n",
      "BB            1296 non-null float64\n",
      "SO            1296 non-null float64\n",
      "SB            1296 non-null float64\n",
      "CS            1296 non-null float64\n",
      "HBP           1296 non-null float64\n",
      "SF            1296 non-null float64\n",
      "RA            1296 non-null int64\n",
      "ER            1296 non-null int64\n",
      "ERA           1296 non-null float64\n",
      "CG            1296 non-null int64\n",
      "SHO           1296 non-null int64\n",
      "SV            1296 non-null int64\n",
      "IPouts        1296 non-null int64\n",
      "HA            1296 non-null int64\n",
      "HRA           1296 non-null int64\n",
      "BBA           1296 non-null int64\n",
      "SOA           1296 non-null int64\n",
      "E             1296 non-null int64\n",
      "DP            1296 non-null int64\n",
      "FP            1296 non-null float64\n",
      "BPF           1296 non-null int64\n",
      "PPF           1296 non-null int64\n",
      "WHIP          1296 non-null float64\n",
      "KBB           1296 non-null float64\n",
      "KAB           1296 non-null float64\n",
      "Bavg          1296 non-null float64\n",
      "Slug          1296 non-null float64\n",
      "OBP           1296 non-null float64\n",
      "OPS           1296 non-null float64\n",
      "dtypes: float64(15), int64(22)\n",
      "memory usage: 384.8 KB\n",
      "Team 2017\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 1294 to 1323\n",
      "Data columns (total 37 columns):\n",
      "Unnamed: 0    30 non-null int64\n",
      "yearID        30 non-null int64\n",
      "R             30 non-null int64\n",
      "AB            30 non-null int64\n",
      "H             30 non-null int64\n",
      "2B            30 non-null int64\n",
      "3B            30 non-null int64\n",
      "HR            30 non-null int64\n",
      "BB            30 non-null float64\n",
      "SO            30 non-null float64\n",
      "SB            30 non-null float64\n",
      "CS            30 non-null float64\n",
      "HBP           30 non-null float64\n",
      "SF            30 non-null float64\n",
      "RA            30 non-null int64\n",
      "ER            30 non-null int64\n",
      "ERA           30 non-null float64\n",
      "CG            30 non-null int64\n",
      "SHO           30 non-null int64\n",
      "SV            30 non-null int64\n",
      "IPouts        30 non-null int64\n",
      "HA            30 non-null int64\n",
      "HRA           30 non-null int64\n",
      "BBA           30 non-null int64\n",
      "SOA           30 non-null int64\n",
      "E             30 non-null int64\n",
      "DP            30 non-null int64\n",
      "FP            30 non-null float64\n",
      "BPF           30 non-null int64\n",
      "PPF           30 non-null int64\n",
      "WHIP          30 non-null float64\n",
      "KBB           30 non-null float64\n",
      "KAB           30 non-null float64\n",
      "Bavg          30 non-null float64\n",
      "Slug          30 non-null float64\n",
      "OBP           30 non-null float64\n",
      "OPS           30 non-null float64\n",
      "dtypes: float64(15), int64(22)\n",
      "memory usage: 8.9 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",

    "team = pd.read_csv('./data/teams2Plus.csv')\n",

    "\n",
    "#Convert Y/N playoff flag to 1/0 indicator\n",
    "team['Playoff'] = team['Playoff'].map({'Y':1, 'N':0})\n",
    "\n",
    "#Drop records with missing values in the Playoff column\n",
    "team = team[np.isfinite(team['Playoff'])]\n",
    "team.Playoff = team.Playoff.astype(int)\n",
    "\n",
    "#Store all franchise IDs per row for future references\n",
    "allfranchID = team['franchID']\n",
    "\n",
    "#Create Y Response Variable DF\n",
    "teamY = team['Playoff']\n",
    "\n",
    "#Drop Categorial Columns with no predictive ability\n",
    "team = team.drop(['teamIDBR', 'teamIDlahman45', 'teamIDretro', 'G', 'teamID', 'Ghome', 'name', 'park', 'lgID', 'divID', 'salary', 'attendance', 'Playoff'], axis=1)\n",
    "\n",
    "#Drop Columns which introduce leakage\n",
    "team = team.drop(['LgWin', 'DivWin', 'WCWin', 'WSWin', 'W', 'L', 'Rank'], axis=1)\n",
    "\n",
    "#Create Cross Validation Object with 10 folds with 80/20 train - test split\n",
    "cv = ShuffleSplit(n_splits = 10, test_size=0.20, random_state=0)\n",
    "\n",
    "#Also create Test set for 2017\n",
    "team2017 = team.loc[team['yearID'] == 2017]\n",
    "franchid2017 = team2017['franchID']\n",
    "\n",
    "#Drop last categorial column now that it has been preserved\n",
    "team = team.drop(['franchID'], axis=1)\n",
    "team2017 = team2017.drop(['franchID'], axis=1)\n",
    "\n",
    "#Create X Explanatory Variables DF to support the individual models\n",
    "teamX = team\n",
    "teamXRfecv = team\n",
    "teamXSVM = team\n",
    "teamXRfecv = teamXRfecv.drop(['Unnamed: 0'], axis=1)\n",
    "teamXSVM = teamXSVM.drop(['Unnamed: 0'], axis=1)\n",
    "print(\"teamXRfecv\", teamXRfecv.info())\n",
    "print(\"teamXSVM\", teamXSVM.info())\n",
    "\n",
    "print(\"Team DF\")\n",
    "team.info()\n",
    "#teamX_colNames = list(teamX)\n",
    "\n",
    "print(\"Team 2017\")\n",
    "team2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "yearID        0\n",
       "R             0\n",
       "AB            0\n",
       "H             0\n",
       "2B            0\n",
       "3B            0\n",
       "HR            0\n",
       "BB            0\n",
       "SO            0\n",
       "SB            0\n",
       "CS            0\n",
       "HBP           0\n",
       "SF            0\n",
       "RA            0\n",
       "ER            0\n",
       "ERA           0\n",
       "CG            0\n",
       "SHO           0\n",
       "SV            0\n",
       "IPouts        0\n",
       "HA            0\n",
       "HRA           0\n",
       "BBA           0\n",
       "SOA           0\n",
       "E             0\n",
       "DP            0\n",
       "FP            0\n",
       "BPF           0\n",
       "PPF           0\n",
       "WHIP          0\n",
       "KBB           0\n",
       "KAB           0\n",
       "Bavg          0\n",
       "Slug          0\n",
       "OBP           0\n",
       "OPS           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last check for NA values\n",
    "team.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colinearity\n",
    "As determined in Lab 1, colinearity is an issue in this data set.  Highly correlated and redundant features will be removed from the input into the \"GridSearchCV Logistic Regression with manual variable reduction\" model.  Though colinearity is a objective measurement, some subjective descretion will be exercised when removing features.  \n",
    "\n",
    "##### Starting Colinearity"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP          E            -0.958084\n",
      "CG          yearID       -0.828620\n",
      "            Unnamed: 0   -0.820053\n",
      "SHO         ERA          -0.669942\n",
      "WHIP        SHO          -0.651043\n",
      "                            ...   \n",
      "KAB         SO            0.973806\n",
      "OPS         Slug          0.974699\n",
      "BPF         PPF           0.978014\n",
      "RA          ER            0.985641\n",
      "Unnamed: 0  yearID        0.999068\n",
      "Length: 666, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Create correlation matrix\n",
    "teamCorrMat = team.corr()\n",
    "\n",
    "# Highest Correlation Pairs\n",
    "corrPairs = teamCorrMat.unstack().sort_values(kind=\"quicksort\")\n",
    "#- REMOVE DUPLICATES\n",
    "corrPairs = corrPairs[::2]\n",
    "corrPairs = corrPairs[corrPairs.index.get_level_values(0) != corrPairs.index.get_level_values(1)]\n",
    "with pd.option_context('display.max_rows',10):\n",
    "    print(corrPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ending Colinearity"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 4,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SV   CG    -0.521343\n",
      "HRA  CG    -0.517123\n",
      "KBB  CG    -0.450180\n",
      "CG   RA    -0.330862\n",
      "R    CG    -0.233253\n",
      "              ...   \n",
      "AB   RA     0.494169\n",
      "HRA  R      0.524398\n",
      "R    AB     0.578170\n",
      "RA   HRA    0.743288\n",
      "OBP  R      0.814649\n",
      "Length: 28, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Drop highly correlated, insignificant and high VIF columns.\n",
    "teamX = team.drop(['CS', 'BB', 'SB', '2B', '3B', 'BBA', 'DP', 'HR', 'yearID', 'WHIP', 'HA', 'HBP', 'Slug', 'SF', 'OPS', 'Bavg', 'SOA', 'KAB', 'SHO', 'FP', 'E', 'ER', 'IPouts', 'SO', 'BPF', 'PPF', 'Unnamed: 0', 'ERA', 'H'], axis=1)\n",
    "\n",
    "#Create correlation matrix\n",
    "teamCorrMat = teamX.corr()\n",
    "\n",
    "# Highest Correlation Pairs\n",
    "corrPairs = teamCorrMat.unstack().sort_values(kind=\"quicksort\")\n",
    "#- REMOVE DUPLICATES\n",
    "corrPairs = corrPairs[::2]\n",
    "corrPairs = corrPairs[corrPairs.index.get_level_values(0) != corrPairs.index.get_level_values(1)]\n",
    "with pd.option_context('display.max_rows',10):\n",
    "    print(corrPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data\n",
    "It is critical to scale this data set for input into each of the three models in this report.  Several features in the data set are decimal measurements that will never exceed 1.  The realistic range of Batting Average is approximately 0.21 to 0.3.  Other features such as attendence could range from tens of thousands to hundreds of thousands.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,

   "metadata": {},

   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scale data\n",
    "scaler = StandardScaler()\n",
    "teamX_scaled = scaler.fit_transform(teamX)\n",
    "teamXRfecv_scaled = scaler.fit_transform(teamXRfecv)\n",
    "teamXSVM_scaled = scaler.fit_transform(teamXSVM)\n",
    "\n",
    "#Save as data frames\n",
    "df_teamX_scaled = pd.DataFrame(teamX_scaled)\n",
    "df_teamXRfecv_scaled = pd.DataFrame(teamXRfecv_scaled)\n",
    "df_teamXSVM_scaled = pd.DataFrame(teamXSVM_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Inflation Factors (VIF)\n",
    "VIF will also be addressed prior to running the \"GridSearchCV Logistic Regression with manual variable reduction\" model.  The starting VIF of the unscaled team data shows several features with high VIF Factors.\n",
    "##### Beginning VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.077363e+03</td>\n",
       "      <td>Unnamed: 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.433994e+06</td>\n",
       "      <td>yearID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.211189e+03</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.266656e+05</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.297657e+05</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.792292e+03</td>\n",
       "      <td>2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.276009e+02</td>\n",
       "      <td>3B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.407856e+04</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.019001e+04</td>\n",
       "      <td>BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.838337e+04</td>\n",
       "      <td>SO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.874866e+01</td>\n",
       "      <td>SB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.059104e+01</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.689668e+02</td>\n",
       "      <td>HBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.277409e+01</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.223108e+03</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.784064e+05</td>\n",
       "      <td>ER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.715971e+05</td>\n",
       "      <td>ERA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.343285e+01</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.402664e+01</td>\n",
       "      <td>SHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.906925e+01</td>\n",
       "      <td>SV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.075035e+05</td>\n",
       "      <td>IPouts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.782902e+05</td>\n",
       "      <td>HA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.030460e+02</td>\n",
       "      <td>HRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.921630e+04</td>\n",
       "      <td>BBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.184049e+03</td>\n",
       "      <td>SOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.862108e+03</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.137754e+02</td>\n",
       "      <td>DP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.891762e+06</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.450697e+04</td>\n",
       "      <td>BPF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.412464e+04</td>\n",
       "      <td>PPF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.135300e+05</td>\n",
       "      <td>WHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9.488985e+02</td>\n",
       "      <td>KBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.803589e+04</td>\n",
       "      <td>KAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.173560e+05</td>\n",
       "      <td>Bavg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>inf</td>\n",
       "      <td>Slug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>inf</td>\n",

       "      <td>OBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>inf</td>\n",
       "      <td>OPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [

       "      VIF Factor    features\n",
       "0   1.077363e+03  Unnamed: 0\n",
       "1   5.433994e+06      yearID\n",
       "2   1.211189e+03           R\n",
       "3   3.266656e+05          AB\n",
       "4   2.297657e+05           H\n",
       "5   4.792292e+03          2B\n",
       "6   3.276009e+02          3B\n",
       "7   1.407856e+04          HR\n",
       "8   2.019001e+04          BB\n",
       "9   3.838337e+04          SO\n",
       "10  1.874866e+01          SB\n",
       "11  3.059104e+01          CS\n",
       "12  1.689668e+02         HBP\n",
       "13  8.277409e+01          SF\n",
       "14  6.223108e+03          RA\n",
       "15  1.784064e+05          ER\n",
       "16  1.715971e+05         ERA\n",
       "17  1.343285e+01          CG\n",
       "18  1.402664e+01         SHO\n",
       "19  4.906925e+01          SV\n",
       "20  2.075035e+05      IPouts\n",
       "21  2.782902e+05          HA\n",
       "22  1.030460e+02         HRA\n",
       "23  3.921630e+04         BBA\n",
       "24  1.184049e+03         SOA\n",
       "25  1.862108e+03           E\n",
       "26  1.137754e+02          DP\n",
       "27  4.891762e+06          FP\n",
       "28  2.450697e+04         BPF\n",
       "29  2.412464e+04         PPF\n",
       "30  5.135300e+05        WHIP\n",
       "31  9.488985e+02         KBB\n",
       "32  3.803589e+04         KAB\n",
       "33  7.173560e+05        Bavg\n",
       "34           inf        Slug\n",
       "35           inf         OBP\n",
       "36           inf         OPS"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "df2_vif = pd.DataFrame()\n",
    "df2_vif[\"VIF Factor\"] = [vif(team.values, i) for i in range(team.shape[1])]\n",
    "#df2_vif[\"features\"] = df_teamX_scaled.columns\n",
    "df2_vif[\"features\"] = team.columns\n",
    "df2_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ending VIF\n",
    "After applying a threshold of 10, the VIF for data input into the manual Logistic Regression model has been reduced significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.395007</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.138265</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.591007</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.977814</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.184272</td>\n",
       "      <td>SV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.826117</td>\n",
       "      <td>HRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.447916</td>\n",
       "      <td>KBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.039360</td>\n",
       "      <td>OBP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF Factor features\n",
       "0    8.395007        R\n",
       "1    3.138265       AB\n",
       "2    5.591007       RA\n",
       "3    2.977814       CG\n",
       "4    2.184272       SV\n",
       "5    3.826117      HRA\n",
       "6    2.447916      KBB\n",
       "7    5.039360      OBP"
      ]
     },

     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Credit to:\n",
    "###https://stats.stackexchange.com/questions/155028/how-to-systematically-remove-collinear-variables-in-python\n",
    "###https://etav.github.io/python/vif_factor_python.html\n",
    "\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "df2_vif = pd.DataFrame()\n",
    "df2_vif[\"VIF Factor\"] = [vif(df_teamX_scaled.values, i) for i in range(df_teamX_scaled.shape[1])]\n",
    "#df2_vif[\"features\"] = df_teamX_scaled.columns\n",
    "df2_vif[\"features\"] = teamX.columns\n",
    "df2_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Feature Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.245847\n",
      "         Iterations 8\n",

      "                          Results: Logit\n",
      "==================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.484      \n",
      "Dependent Variable: Playoff          AIC:              653.2342   \n",
      "Date:               2018-06-17 19:57 BIC:              694.5705   \n",
      "No. Observations:   1296             Log-Likelihood:   -318.62    \n",
      "Df Model:           7                LL-Null:          -618.03    \n",
      "Df Residuals:       1288             LLR p-value:      4.3796e-125\n",
      "Converged:          1.0000           Scale:            1.0000     \n",
      "No. Iterations:     8.0000                                        \n",
      "---------------------------------------------------------------------\n",
      "        Coef.     Std.Err.       z       P>|z|      [0.025     0.975]\n",
      "---------------------------------------------------------------------\n",
      "R       0.0274      0.0022    12.5624    0.0000     0.0231     0.0317\n",
      "AB     -0.0027      0.0005    -5.7628    0.0000    -0.0036    -0.0018\n",
      "RA     -0.0202      0.0027    -7.4099    0.0000    -0.0255    -0.0148\n",
      "CG      0.0340      0.0110     3.0870    0.0020     0.0124     0.0556\n",
      "SV      0.1128      0.0169     6.6873    0.0000     0.0797     0.1458\n",
      "HRA    -0.0145      0.0058    -2.4878    0.0129    -0.0260    -0.0031\n",
      "KBB     1.0381      0.3281     3.1643    0.0016     0.3951     1.6810\n",
      "OBP     3.7713      4.4626     0.8451    0.3981    -4.9753    12.5179\n",
      "==================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Summary table with full model fit prior to scaling, cross validation or recursive \n",
    "#feature elimination.\n",
    "#Cursory check to verify feature significance\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model = sm.Logit(teamY, teamX)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,

   "metadata": {},

   "outputs": [],
   "source": [
    "#Credit To:  https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "results = []\n",
    "\n",
    "def EvaluateClassifierEstimator(classifierEstimator, X, y, cv, model):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, teamX, teamY, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "    \n",
    "    results.append({'Model': model, 'Accuracy': Accavg, 'Precision': Preavg, 'Recall': Recavg})\n",
    "\n",
    "    return scoresResults\n",
    "\n",
    "def EvaluateClassifierEstimator2(classifierEstimator, X, y, cv):\n",
    "    \n",
    "    #Perform cross validation \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predictions = cross_val_predict(classifierEstimator, teamX, teamY, cv=cv)\n",
    "    \n",
    "    #model evaluation \n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    \n",
    "    #pass true test set values and predictions to classification_report\n",
    "    classReport = classification_report(Y,predictions)\n",
    "    confMat = confusion_matrix(Y,predictions)\n",
    "    acc = accuracy_score(Y,predictions)\n",
    "    \n",
    "    print (classReport)\n",
    "    print (confMat)\n",
    "    print (acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV Logistic Regression with Manual Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [

      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:    5.7s finished\n"

     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.2, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'class_weight': ['balanced', 'none'], 'random_state': [0], 'solver': ['lbfgs'], 'max_iter': [100, 500]},\n",

       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logisitic regression 10-fold cross-validation \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "#regGridSearch.fit(teamX, teamY)\n",
    "regGridSearch.fit(df_teamX_scaled, teamY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.60519102, -0.76252932, -1.97336804,  0.53512682,  1.0217957 ,\n",
       "        -0.51143328,  0.46728398,  0.06831141]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diplay the top model parameters\n",
    "regGridSearch.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.89385\n",

      "The average precision for all cv folds is: \t\t\t 0.76677\n",
      "The average recall for all cv folds is: \t\t\t 0.60859\n",

      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.698113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.673077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.508772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.892308   0.736842  0.608696\n",
       "1  0.888462   0.757576  0.543478\n",
       "2  0.907692   0.822222  0.698113\n",
       "3  0.888462   0.775510  0.678571\n",
       "4  0.907692   0.833333  0.673077\n",
       "5  0.900000   0.777778  0.608696\n",
       "6  0.850000   0.725000  0.508772\n",
       "7  0.896154   0.750000  0.558140\n",
       "8  0.900000   0.789474  0.625000\n",
       "9  0.907692   0.700000  0.583333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the best parameters for our Linear Regression object\n",
    "classifierEst = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateClassifierEstimator(classifierEst, df_teamX_scaled, teamY, cv, \"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator GridSearch Prediction\n",
      "[0 1 0 ... 0 0 1]\n",
      "[[0.994294   0.005706  ]\n",
      " [0.08913697 0.91086303]\n",
      " [0.66284756 0.33715244]\n",
      " ...\n",
      " [0.99568585 0.00431415]\n",
      " [0.99548092 0.00451908]\n",
      " [0.26457073 0.73542927]]\n"
     ]
    }
   ],
   "source": [
    "#Predictions using Grid Search CV\n",
    "#print(\"Plain GridSearch Prediction\")\n",
    "#print(regGridSearch.predict(teamX))\n",
    "#print(regGridSearch.predict_proba(teamX))\n",
    "#print(regGridSearch.predict(df_teamX_scaled))\n",
    "#print(regGridSearch.predict_proba(df_teamX_scaled))\n",
    "\n",
    "#Is there a difference between .predict and .best_estimator_.predict?  Nope.\n",
    "print(\"Best Estimator GridSearch Prediction\")\n",
    "#print(regGridSearch.best_estimator_.predict(teamX))\n",
    "#print(regGridSearch.best_estimator_.predict_proba(teamX))\n",
    "print(regGridSearch.best_estimator_.predict(df_teamX_scaled))\n",
    "print(regGridSearch.best_estimator_.predict_proba(df_teamX_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV Logistic Regression with Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV Logistic Regression 1st Pass\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Ranking [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Support [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n",
      "Number of Features: 35\n",
      "Logistic Regression Second Pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.2, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__penalty': ['l2'], 'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'logisticregression__class_weight': ['balanced', 'none'], 'logisticregression__random_state': [0], 'logisticregression__solver': ['lbfgs'], 'logisticregression__max_iter': [100, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Credit to:  Jake Drew NC Education Data Set Analysis\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "print(\"RFECV Logistic Regression 1st Pass\")\n",
    "rfecvEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfecvGridSearch = GridSearchCV(estimator=rfecvEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data using RFECV\n",
    "rfecvGridSearch.fit(df_teamXRfecv_scaled, teamY)\n",
    "\n",
    "#Use the best parameters for our RFECV Linear Regression object\n",
    "rfecvClassifierEst = rfecvGridSearch.best_estimator_\n",
    "\n",
    "#Recursive Feature Elimination\n",
    "rfecv = RFECV(estimator=rfecvClassifierEst, step=1, cv=cv, scoring='accuracy', verbose=1)\n",
    "#X_BestFeatures = rfecv.fit_transform(teamX, teamY)\n",
    "X_BestFeatures = rfecv.fit_transform(df_teamXRfecv_scaled, teamY)\n",
    "\n",
    "#Print RFECV Details\n",
    "print(\"Ranking\", rfecv.ranking_)\n",
    "print(\"Support\", rfecv.support_)\n",
    "print(\"Number of Features:\", rfecv.n_features_)\n",
    "\n",
    "print(\"Logistic Regression Second Pass\")\n",
    "#create a pipeline to scale all of the data and perform logistic regression during each grid search step.\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "#Define a range of hyper parameters for grid search\n",
    "parameters = { 'logisticregression__penalty':['l2']\n",
    "              ,'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'logisticregression__class_weight': ['balanced','none']\n",
    "              ,'logisticregression__random_state': [0]\n",
    "              ,'logisticregression__solver': ['lbfgs']\n",
    "              ,'logisticregression__max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(pipe, parameters, cv=cv, scoring='accuracy')\n",
    "\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "grid.fit(df_teamXRfecv_scaled, teamY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.88846\n",
      "The average precision for all cv folds is: \t\t\t 0.75864\n",
      "The average recall for all cv folds is: \t\t\t 0.58567\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.641509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.508772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.892308   0.736842  0.608696\n",
       "1  0.888462   0.757576  0.543478\n",
       "2  0.884615   0.755556  0.641509\n",
       "3  0.865385   0.723404  0.607143\n",
       "4  0.900000   0.842105  0.615385\n",
       "5  0.896154   0.787879  0.565217\n",
       "6  0.853846   0.743590  0.508772\n",
       "7  0.896154   0.750000  0.558140\n",
       "8  0.900000   0.789474  0.625000\n",
       "9  0.907692   0.700000  0.583333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the best parameters from RFECV for our Linear Regression object\n",
    "#rfecvClassifierEst = grid.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "#EvaluateClassifierEstimator(classifierEst, teamX, teamY, cv)\n",
    "EvaluateClassifierEstimator(rfecvClassifierEst, df_teamXRfecv_scaled, teamY, cv, 'Rfecv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n",
      "[[0.99643666 0.00356334]\n",
      " [0.07119376 0.92880624]\n",
      " [0.80903794 0.19096206]\n",
      " ...\n",
      " [0.99503012 0.00496988]\n",
      " [0.99604494 0.00395506]\n",
      " [0.31206208 0.68793792]]\n"
     ]
    }
   ],
   "source": [
    "#print(grid.best_estimator_.predict(teamX))\n",
    "#print(grid.best_estimator_.predict_proba(teamX))\n",
    "print(grid.best_estimator_.predict(df_teamXRfecv_scaled))\n",
    "print(grid.best_estimator_.predict_proba(df_teamXRfecv_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8865740740740741\n",
      "precision: 0.837037037037037\n",
      "recall: 0.47478991596638653\n",
      "[[1036   22]\n",
      " [ 125  113]]\n"
     ]
    }
   ],
   "source": [
    "#SVM for consolidated team level baseball data created in Lab 1.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#teamX_scaled = scaler.fit_transform(teamX)\n",
    "\n",
    "#train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(df_teamXSVM_scaled, teamY)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(df_teamXSVM_scaled)\n",
    "\n",
    "acc = mt.accuracy_score(teamY,y_hat)\n",
    "conf = mt.confusion_matrix(teamY,y_hat)\n",
    "prec = mt.precision_score(teamY, y_hat)\n",
    "recall = mt.recall_score(teamY, y_hat)\n",
    "print('accuracy:', acc )\n",
    "print('precision:', prec)\n",
    "print('recall:', recall)\n",
    "print(conf)\n",
    "\n",
    "results.append({'Model': 'SVM', 'Accuracy': acc, 'Precision': prec, 'Recall': recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484, 36)\n",
      "(484,)\n",
      "[257 227]\n"
     ]
    }
   ],
   "source": [
    "#look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# SVM based Prediction\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Summary\n",
    "All three planned models were sucessfully implemented as planned.  All models utilized cross validation to control results.  Stochastic Gradient Descent was not utilized for the support vector machine model as the size of the data set did not warrant it use.  Good results were achieved by all models.  The \"GridSearchCV Logistic Regression with manual variable reduction\" model ultimately produced the best accuracy and overall results.  The results are summarized in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manual</td>\n",
       "      <td>0.893846</td>\n",
       "      <td>0.766774</td>\n",
       "      <td>0.608588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rfecv</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.758643</td>\n",
       "      <td>0.585667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.474790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  Precision    Recall\n",
       "0  manual  0.893846   0.766774  0.608588\n",
       "1   Rfecv  0.888462   0.758643  0.585667\n",
       "2     SVM  0.886574   0.837037  0.474790"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results[['Model', 'Accuracy', 'Precision', 'Recall']]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression and support vector machines are both machine learning models used for classification and regression analysis. Logistic regression's algorithm is centered on maximizing the probability of the data. The logistic regression model's accuracy is best when the data lies far from the separating line or hyperplane. The SVM algorithm is centered on finding the separating line or hyperplane that maximizes the distance the closest points are to the margin, known as the support vectors. These goals cause the logistic regression to be probabilistic, while SVMs are deterministic. We used two different types of logistic regression models. The first model used manual variable selection; we used correlation scores, variable inflation factors and significance scores to manually reduce the number of features input into the regression function. The manual logistic regression model time was much faster than the recursive feature elimination model. The recursive model repeatedly constructs a model and chooses the best or worst performing feature, puts that feature aside, then repeats the process until all variables have been analyzed. Since it analyzes every variable, this model takes more time to run than the manual model. Similarly, the SVM model analyses all variables so it also takes much more time to run the model.\n",
    "\n",
    "Another aspect to evaluate is the amount of time needed to create, tune and optimize the models. The manual logistic regression model does use GridSearchCV to automate parameter selection. However, the individual features must be examined and tested manually to find the best model. This requires quite a bit of human capital to complete. Conversely, the RFE and SVM models do the feature selection automatically. After the initial programming is complete, the time needed to tune the RFE and SVM models is minimal compared to the manual model. In an agile environment, RFE and/or SVM could be used to produce a quality model quickly to solve a business problem while alternative models are being developed or prototyped.\n",
    "\n",
    "There are advantages associated with both models. Overall, and as seen in our outcome, logistic regression and SVMs perform relatively similarly. We can see this in our accuracy, the logistic regression models and SVM model's accuracy are all within 1% accuracy of the other. The highest performing model in terms of accuracy was the manual logistic regression model with 89.39% accuracy. We can also compare these models in terms of precision and recall. Recall is defined as the correctly classified events to the number of all correct events. Precision measures the events correctly recalled to all events recalled; it is measuring how precise the recalls are. In our models, the precision was much higher in the SVM model with 83.7% precision. The logistic regression models performed very similarly to one another with manual having 76.71% precision and the RFE model having 75.86% precision. The manual logistic regression model performed much better than the others in terms of recall, 61.22%. The RFE model had a recall ratio of 58.56%, while the SVM only had a recall ratio of 47.47%. Comparing all three models, the manual logistic regression model seemed to perform the best for our data. It was faster than the other models, had the highest accuracy and recall, and performed very closely with precision.\n",
    "\n",
    "The intended use of the model could also impact the decision. If the model is to serve a one-time need, the manual model would likely be the correct choice with it high accuracy and all-around results. However, if the model is intended to be implemented in a production environment and run on a routine basis, SVM and the RFE model may be a better choice. Both models can optimize feature selection as more data is collected with little human intervention. The manual model must be reviewed and maintained manually to assure optimal results are returned. In the end, the problem to be solved must be understood to select the appropriate classification model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key References\n",
    "\n",
    "https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb\n",
    "https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb (Logit)\n",
    "http://www.cs.toronto.edu/~kswersky/wp-content/uploads/svm_vs_lr.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature Importance for Logistic Regression\n",
    "By taking a closer look the feature weights in the logistic models we can get a better idea of which variables are the most important drivers of a team making it to the playoffs.\n",
    "\n",
    "*need some interpretation for final models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plotCoef(coef, names, t):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names), key=lambda x: abs(x[0])))\n",
    "    plt.figure(figsize=(9,12))\n",
    "    barlist = plt.barh(range(len(names)), imp, align='center')\n",
    "    for x in np.nditer(np.where(np.asarray(list(imp)) < 0)):\n",
    "        barlist[x].set_color('r')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.title(t)\n",
    "    plt.show()\n",
    "\n",
    "plotCoef(regGridSearch.best_estimator_.coef_[0], teamX.columns.values, \"Manual Logistic Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.9733680431522715, 'RA'),\n",
       " (-0.7625293211443834, 'AB'),\n",
       " (-0.5114332840188432, 'HRA'),\n",
       " (0.06831140574963632, 'OBP'),\n",
       " (0.46728398442347047, 'KBB'),\n",
       " (0.53512681572117, 'CG'),\n",
       " (1.0217957001327966, 'SV'),\n",
       " (2.605191019202166, 'R')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(zip(regGridSearch.best_estimator_.coef_.ravel(), teamX.columns.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAK7CAYAAAA6I28RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XuYZFV97//3h5Grgxql7VakmYgIKuqIbVDiBcVEjmKEaBTiScCYtPn9ctPEJGhMJDlROTFqjB5PMkkUSRQ0UZRIzDFHxUtEY6MDiBfIhPGCztBcFEZGxOF7/qjdWhTdw1y6qvbueb+ep56pWmvvXd/qdpiPa63aK1WFJElSV+w17gIkSZJ2huFFkiR1iuFFkiR1iuFFkiR1iuFFkiR1iuFFkiR1iuFF2sMl+WCS08Zdx45I8vIkf7uL525J8sDlrknS6MX7vEjDk2QjMAlsA7YA/wr8elVtGWddo5CkgMOr6j/H8N4XAf9QVbsUdPqucxzwEeCWvuaPVtUzd/O6ZwPfqKpX7M51pD2VIy/S8D2zqlYDa4FHAS8b5Zsnudso328F+mZVre577FZwWQ7+TrWnM7xII1JVm4D/Qy/EAJBk3yR/nuRrSTYn+ask+/f1PyvJ+iQ3JdmQ5ISmfWOSp/Ydd2aSf2ier0lSSV6Y5GvAR5Lsl+Qfklyf5NtJPptksjn+oiS/3NTy7SRH9V13IsnWJPdtXp/Y1PPtJJ9K8oid/Tkk2SvJK5J8Ncm1Sc5Jcs++/l9s+q5P8of9n3Xgcy76mZK8CngC8OZmqujNzfGV5EHN8/2TvK55n+8k+WT/z30nPscZze/l+iTvTnLvvv5/TLKpuf7HkzysaZ8Fng/8XlPfPw/W17w+O8mfNs+PS/KNJL+fZBPwtrv6fTTHXpPk5iRfSXL8znw+qc0ML9KIJHkA8N+A/mmU/wk8mF6geRBwMPBHzfE/AZwD/C5wL+CJwMadeMsnAQ8BngacBtwTOAS4D/CrwNb+g6vqVuC9wKl9zc8FPlZV1yY5Gngr8KLmGn8NXJBk352oCeD05vFk4IHAamAhYDwUeAu9f9zv19R88BLXWfQzVdUfAJ+gNz23uqp+fZFz/xx4NHAscG/g94Dbd/Jz/CZwEr2f8/2BG4H/1df/QeBw4L7A54B3AFTVuub5n+3kSM5UU+uhwOz2fh9JjgB+HXhMVR1I738DG3fy80mtZXiRhu99SW4Gvg5cC7wSIEmAXwFeUlU3VNXNwKuBU5rzXgi8tar+rapur6prqurLO/G+Z1bVd6tqK3AbvX/gHlRV26rqkqq6aZFz3skdw8vPN200tf51VX2mucbbgVuBx+5ETdALJq+vqv9q1v68DDilmQp5DvDPVfXJqvo+vSC31MK8Hf1Md5BkL+CXgN9qfqbbqupTTXhbzP2bkY2Fx3Ob9hcBf1BV32jOPRN4zsKUTlW9tapu7ut7ZP8I0y64HXhlVd3a/E639/vYBuwLPDTJ3lW1sao27MZ7S61ieJGG76Tm//0eBxwJHNS0TwAHAJcs/MNIb0HvRNN/CLA7/+B8ve/539ObsjovyTeT/FmSvRc55yPA/kmOSXIovRGh85u+Q4Hf6f+HvKnx/jtZ1/2Br/a9/ipwN3oLm+/fX3dV3QJcv8R1dvQzDToI2I8d/9l+s6ru1fd4d9N+KHB+38/iS/RCw2SSVUnOaqaUbuJHox4H3fnyO2y+qr7X93rJ30ezSPrF9ELTtUnOS7KzvyeptQwv0ohU1ceAs+lNWQBcR2/q5mF9/zDes1ncC71/xA9b4nLfpRd8Fkwt9pZ9731bVf1xVT2U3lTJicAvLlLj7cC76Y2+/DzwgWZEaKGeVw38Q35AVZ17lx/+jr5J7x/eBdPAD4DNwLeAByx0NOtQ7rPYRe7iM23va5TXAd9j6Z/tjvo68N8Gfh77VdU19H52zwKeSm9qa83CR9pOfbew/d/p4Dnb/X1U1Tur6vH0ftZFb4pSWhEML9Jo/QXwU0nWNkHhb4A39C2IPTjJ05pj/w54QZLjm8WhByc5sulbT2+qZe8kM/SmW5aU5MlJHp5kFXATvSmXbUsc/k7gefSmd97Z1/43wK82ozJJcvckz0hy4Hbeep9mYe3CYxVwLvCSJD+eZDW9qbJ3VdUPgH8Cnpnk2CT7AH/Mj/7B35nPtJneepo7aX7ubwVen+T+zSjJ43Zh7c5fAa9qRqgWFjc/q+k7kN4UzvX0AsmrB85drL71wM839ZxAby3N9iz5+0hyRJKnNJ/pe/RC8lK/b6lzDC/SCFXVPL1FuH/YNP0+vQW8n26mF/4vcERz7H8ALwDeAHwH+Bg/GrH4Q3ojBzfS+we+P2QsZopeMLiJ3vTGx4B/WKLGz9Ab2bk/vUWnC+1z9NZZvLl53/+kt/B2e66g9w/nwuMF9ILD3wMfB66m94/rbzTvcUXz/Dx6ozA301sntNh6lO19pjfSW39yY5K/XOTclwKXA58FbqA3KrGz/z18I3AB8KFmTdOngWOavnPoTYddA3yx6ev3d/TWo3w7yfuatt8Cngl8m15wfB/bcRe/j32Bs+iNMm2it2j45Tv5+aTW8iZ1klqrGZn5Nr2b3V097noktYMjL5JaJckzkxyQ5O701gddjl/zldTH8CKpbZ5Fb1HvN+ndJ+WUcohYUh+njSRJUqc48iJJkjql05t7HXTQQbVmzZpxlyFJkpbBJZdccl1VTdzVcZ0OL2vWrGFubm7cZUiSpGWQ5Kt3fZTTRpIkqWMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVMML5IkqVPuNu4CJGl71pxx4bhLkNRn41nPGHcJjrxIkqRuMbxIkqROWfbwkuQPklyR5LIk65Mck+SiJDPL/V6SJGnPs6xrXpI8DjgROLqqbk1yELDPcr6HJEnasy33yMv9gOuq6laAqrquqr7Zf0CSLX3Pn5Pk7Ob5YUk+neSzSf6k/zhJkqQFyx1ePgQckuTKJG9J8qSdOPeNwBur6jHAN+/qYEmStGda1vBSVVuARwOzwDzwriSn7+DpjwP+sXn+zqUOSjKbZC7J3Pz8/O6UK0mSOmjZ7/NSVduAi4CLklwOnDZ4SN/z/Xbh+uuAdQAzMzN1F4dLkqQVZllHXpIckeTwvqa1wFcHDtuc5CFJ9gJO7mv/NPDs5vkpy1mXJElaOZZ7zctq4O1JvpjkMuChwJkDx5wBfAD4CPCtvvYXA7+d5D/oLfz9zjLXJkmSVoBlnTaqqkuAYxfpOq7vmH8C/mmRY64BHltVleQUYG45a5MkSStDm/Y2ejTw5iQBvg380pjrkSRJLdSa8FJVnwAeOe46JLVLGzaBk9Qu7m0kSZI6xfAiSZI6xfAiSZI6pTVrXiRpMWvOuHDcJUiiXevPHHmRJEmdYniRJEmdMvLwkuQPklyR5LIk65Mck2SfJH+RZEOSq5K8P8kDRl2bJElqv5GueUnyOOBE4OiqujXJQcA+wKuBA4EHV9W2JC8A3pvkmKpy80VJkvRDox55uR9wXVXdClBV19G7m+4LgJc0O1JTVW8DbgWeMuL6JElSy406vHwIOCTJlUnekuRJwIOAr1XVTQPHzgEPG7xAktkkc0nm5ufnR1CyJElqk5GGl6raQm8Po1lgHngX8GRgsamhLNZeVeuqaqaqZiYmJoZZriRJaqGR3+elmRq6CLgoyeXAi4BDkxxYVTf3HXo08M+jrk+SJLXbSEdekhyR5PC+prXAV4C3A69Psqo57heBA4CPjLI+SZLUfqMeeVkNvCnJvYAfAP9JbwrpZuDPgSuT3A58GTjZbxpJkqRBIw0vVXUJcOwS3b/RPCRJkpbkHXYlSVKnuDGjpFZr02ZwktrBkRdJktQphhdJktQpThstZWoKNm8edxWSJidh06ZxVyGpRRx5WYrBRWoH/y5KGmB4kSRJnWJ4kSRJnTLq7QG2DLw+Pcmbm+dnJrkmyfokX0xy6ihrkyRJ3dC2kZc3VNVa4FnAXyfZe9wFSZKkdmlbeAGgqq4CbgF+bNy1SJKkdhn1V6X3T7K+7/W9gQsGD0pyNHBVVV27SN8svc0cmZ6eHladkiSppUYdXrY200JAb80LMNPX/5IkvwI8EDhhsQtU1TpgHcDMzIy7TkuStIdp27TRG6rqCOB5wDlJ9ht3QZIkqV3aFl4AqKr3AnPAaeOuRZIktUsrw0vjT4DfTtLmGiVJ0oilqrvLRmZmZmpubm44F0+Gc11JO6/D/52StOOSXFJVM3d1nKMakiSpUwwvS5mcHHcFksC/i5LuZNRfle6OTZvGXYEkSVqEIy+SJKlTHHlZTlNTsHnzuKuQVpbJSUdCJd2BIy/LyeAiLT//XkkaYHiRJEmdMvLwkuTkJJXkyOb1miRbk6xPcmmSTyU5YtR1SZKkbhjHyMupwCeBU/raNlTV2qp6JPB24OVjqEuSJHXASMNLktXATwIv5I7hpd89gBtHVpQkSeqUUX/b6CTgX6vqyiQ3JDkauAE4LMl64EDgAOCYpS6QZBaYBZienh5ByZIkqU1GPW10KnBe8/y85jX8aNroMODFwLqlLlBV66pqpqpmJiYmhlutJElqnZGNvCS5D/AU4KgkBawCCnjLwKEXAG8bVV2SJKlbRjny8hzgnKo6tKrWVNUhwNXAAwaOezywYYR1SZKkDhnlmpdTgbMG2t5D75tFC2teAnwf+OUR1iVJkjpkZOGlqo5bpO0vgb8cVQ2SJKn7vMOuJEnqFMPLcpqcHHcF0srj3ytJA9xVejm5860kSUPnyIskSeoUR16W29QUbN487iqklWNy0lFNSXfgyMtyM7hIy8u/U5IGGF4kSVKnGF4kSVKnDCW8JNnS9/zpSa5KMt3XdmmScwfOOTvJ1UnWJ/lyklcOozZJktRtQx15SXI88CbghKr6WtP2kOZ9n5jk7gOn/G5VrQXWAqcl+fFh1idJkrpnaOElyROAvwGeUVX9Gy3+PPD3wIeAn1ni9P2aP787rPokSVI3DSu87Au8Hzipqr480Pc84F3AufQ2a+z32maDxm8A51XVtYMXTjKbZC7J3Pz8/BBKlyRJbTas8HIb8Cnghf2NSR4DzFfVV4EPA0cn+bG+QxamjaaA45McO3jhqlpXVTNVNTMxMTGk8iVJUlsNK7zcDjwXeEySl/e1nwocmWQjsAG4B/DswZOragtwEfD4IdUnSZI6amhrXqrqFuBE4PlJXphkL+DngEdU1ZqqWgM8iztPHZHkbsAx9AKOJEnSDw11e4CquiHJCcDHgeuAa6rqmr5DPg48NMn9mtevTfIKYB9600rvHWZ9kiSpe4YSXqpqdd/zrwMLX3l+/8Bx24CF4HL6MGqRJEkri3fYlSRJnWJ4WW6Tk+OuQFpZ/DslacBQ17zskTZtGncFkiStaI68SJKkTnHkRVKrrTnjwnGXoJbaeNYzxl2CxsSRF0mS1CmGF0mS1CnD3FX6AUnen+SqJBuSvDHJPkmOS/KdJJ9P8qUkr2yOPyDJO5JcnuQLST6ZZPVdvY8kSdqzDCW8JAm9u+O+r6oOBx4MrAZe1Rzyiap6FDAD/PckjwZ+C9hcVQ+vqqPobep42zDqkyRJ3TWsBbtPAb5XVW+D3p10k7wEuBr46MJBVfXdJJcAh9G70+5X+/q+MqTaJElShw1r2uhhwCX9DVV1E/A14EELbUnuAzwWuAJ4K/D7SS5O8qdJDh9SbZIkqcOGNfISoLbT/oQknwduB86qqisAkjwQ+GngqcBnkzyuqr50hwsks8AswPT09JDKlyRJbTWs8HIF8Oz+hiT3AA4BNtBb83Li4ElVtYXeWpn3JrkdeDrwpYFj1gHrAGZmZhYLSJIkaQUb1rTRh4EDkvwiQJJVwOuAs4FbFjshyU8m+bHm+T7AQ+lbAyNJkgRDCi9VVcDJwM8luQq4Evge8PLtnHYY8LEklwOfB+aA9wyjPkmS1F1D2x6gqr4OPHORrouax+Dx5wDnDKseSZK0MniHXUmS1CluzCip1dx8T9IgR14kSVKnGF4kSVKnGF4kSVKnuOZF6jc1BZs3j7sK9ZuchE2bxl2FpBZx5EXqZ3BpH38nkgYYXiRJUqcMJbwkeUCS9ye5KsmGJG9Msk+S45J8J8n6JJcl+b9J7tucc3qS+abvi0l+ZRi1SZKkblv28JIk9DZXfF9VHQ48GFgNvKo55BNVtbaqHgF8Fvi1vtPfVVVrgeOAVyeZXO76JElStw1j5OUpwPeq6m0AVbUNeAnwS8ABCwc1IedA4MbBC1TVtfR2nz50CPVJkqQOG8a3jR4GXNLfUFU3Jfka8CDgCUnWA/cBvssimzUmeSDwQOA/F+mbBWYBpqenl714SZLUbsMYeQlQ22lfmDY6BHgb8Gd9xzyvCTbnAi+qqhsGL1JV66pqpqpmJiYmhlC+JElqs2GMvFwBPLu/Ick9gEPoTQX1uwB4T9/rd1XVrw+hJkmStEIMY+Tlw8ABSX4RIMkq4HXA2cAtA8c+njsHGkmSpCUte3ipqgJOBn4uyVXAlcD3+NHalic0X4e+FPgF4HeWuwZJkrRyDWV7gKr6OvDMRbouAu65xDln0xudkSRJWpJ32JUkSZ1ieJH6TXpfxNbxdyJpgLtKS/3cvViSWs+RF0mS1CmOvEi7amoKNm8edxUr3+SkI2KS7sCRF2lXGVxGw5+zpAGGF0mS1CkjDy9JDkny0SRfSnJFkt9q2s9OcnVzA7svJ3nlqGuTJEntN441Lz8AfqeqPpfkQOCSJP/W9P1uVf1Tkv2ALyY5p6quHkONkiSppUYeXqrqW8C3muc3J/kScPDAYfs1f353lLVJkqT2G+ualyRrgEcBn2maXptkPfAN4LyqunZMpUmSpJYaW3hJshp4D/Diqrqpaf7dqloLTAHHJzl2kfNmk8wlmZufnx9hxZIkqQ3GEl6S7E0vuLyjqt472F9VW+ht4vj4RfrWVdVMVc1MTEwMvVZJktQu4/i2UYC/A75UVa9f4pi7AccAG0ZZmyRJar9xjLz8JPALwFOar0WvT/L0pm9hzctlwOXAnUZlJEnSnm0c3zb6JJBFuv5l1LVIkqTu8Q67kiSpUwwv0q6anBx3BXsGf86SBrirtLSr3OlYksbCkRdJktQphhdJktQpThtJarU1Z1w47hJWpI1nPWPcJUi7zJEXSZLUKYYXSZLUKa2ZNkqyjd5dde8GXA38QlV9e7xVSZKktmnTyMvWqlpbVUcBNwC/Nu6CJElS+7QpvPS7GDh43EVIkqT2aV14SbIKOB64YIn+2SRzSebm5+dHW5wkSRq7NoWX/Zsdpa8H7g3822IHVdW6qpqpqpmJiYmRFihJksavTeFla1WtBQ4F9sE1L5IkaRFtCi8AVNV3gN8EXppk73HXI0mS2qV14QWgqj4PXAqcMu5aJElSu7TmPi9VtXrg9TPHVYskSWqvVo68SJIkLaU1Iy+StBg3EJQ0yJEXSZLUKYYXSZLUKU4bSWq1NWdcOO4SVhSn4bQSOPIiSZI6xfAiSZI6xfAiSZI6ZafCS5ItzZ9rkmxNsj7JF5P8VZJdCkJJXpzkgF05V5Ik7Xl2Z+RlQ7OR4iOAhwIn7eJ1XgwYXiRJ0g7Z7WmjqvoB8CngQel5bZIvJLk8yfMAkhyX5AML5yR5c5LTk/wmcH/go0k+mmRVkrP7zn/J7tYnSZJWlt3+qnQz5XM88EfAzwJrgUcCBwGfTfLxpc6tqr9M8tvAk6vquiSPBg6uqqOaa99rkfebBWYBpqend7d8SZLUMbsz8nJYkvXAvwMXVtUHgccD51bVtqraDHwMeMxOXPO/gAcmeVOSE4CbBg+oqnVVNVNVMxMTE7tRviRJ6qLdGXlZWPPSL0sc+wPuGJT2W+ygqroxySOBpwG/BjwX+KXdqFGSJK0wy/1V6Y8Dz2vWrkwATwT+A/gq8NAk+ya5J71ppgU3AwcCJDkI2Kuq3gP8IXD0MtcnSZI6brm3BzgfeBxwKVDA71XVJoAk7wYuA64CPt93zjrgg0m+Re+bR2/r+9r1y5a5PkmS1HE7FV6qanXz50bgqEX6C/jd5jHY93vA7y3S/ibgTX1NjrZIkqQluTGjpFZzI0FJg9weQJIkdYrhRZIkdYrhRZIkdYprXiS12pozLhx3CSuCa4e0kjjyIkmSOsXwIkmSOmWk4SXJloHXpyd580DbpUnOHWVdkiSpO1o18pLkIfRqemKSu4+7HkmS1D6tCi/AzwN/D3wI+Jkx1yJJklpo1N822j/J+r7X9wYu6Hv9POCngCOAXwfuNH2UZBaYBZienh5epZIkqZVGPfKytarWLjyAP1roSPIYYL6qvgp8GDg6yY8NXqCq1lXVTFXNTExMjK5ySZLUCm2aNjoVODLJRmADcA/g2WOtSJIktU4rwkuSvYCfAx5RVWuqag3wLHqBRpIk6YdaEV6AJwLXVNU1fW0fBx6a5H5jqkmSJLXQSBfsVtXqgddnA2c3Lx870LcNMLhIkqQ7aMvIiyRJ0g5xY0ZJreaGgpIGOfIiSZI6xfAiSZI6xWkjaRSmpmDz5nFX0U2Tk7Bp07irkNQijrxIo2Bw2XX+7CQNMLxIkqROMbxIkqRO2e3wkmRbkvVJLk3yuSTHLkdhkiRJi1mOBbtbmx2iSfI04DXAk5bhupIkSXey3NNG9wBuBEiyOsmHm9GYy5M8q2n/n0n+/4UTkpyZ5HeS7JXkLUmuSPKBJP+S5DnLXJ8kSeq45Rh52T/JemA/ensRPaVp/x5wclXdlOQg4NNJLgDOA/4CeEtz3HOBE4CfBdYADwfuC3wJeOvgmyWZBWYBpqenl6F8SZLUJcsx8rK1qtZW1ZH0Qsg5SQIEeHWSy4D/CxwMTFbV54H7Jrl/kkcCN1bV14DHA/9YVbdX1Sbgo4u9WVWtq6qZqpqZmJhYhvIlSVKXLOtN6qrq4maUZQJ4evPno6vqtiQb6Y3OAPwT8Bxgit5IDPTCjiRJ0nYt65qXJEcCq4DrgXsC1zbB5cnAoX2HngecQi/A/FPT9kng2c3al0nguOWsTZIkrQzLueYFeqMnp1XVtiTvAP45yRywHvjywglVdUWSA4FrqupbTfN7gOOBLwBXAp8BvrMM9UmSpBVkt8NLVa1aov064HHbOe/hA69vT/LSqtqS5D7AfwCX7259kiRpZWnbxowfSHIvYB/gfzQLdyVJkn6oVeGlqo4bdw3SUExOusHgrpqcHHcFklqmVeFFWrE2OYgoScvFjRklSVKnOPIijdrUlFNIO2Ny0pErSXfgyIs0agaXnePPS9IAw4skSeqUXQ4vSd6Q5MV9r/9Pkr/te/26JL+d5AsD552Z5KXN87MXdo5OclGSryS5NMm/JzliV2uTJEkr1+6MvHwKOBYgyV7AQcDD+vqPBf59J6/5/Kp6JPB24LW7UZskSVqhdie8/DtNeKEXWr4A3Jzkx5LsCzwEuHEXr/1x4EG7UZskSVqhdvnbRlX1zSQ/SDJNL8RcDBxMb0uA7wCXAd8HDuvb+wh6O0n/+V1c/pm4NYAkSVrE7n5VemH05Vjg9fTCy7H0wsunmmM2VNXahROSnLmd670jyVZgI/Abix2QZBaYBZient696iVJUufs7reNFta9PJzetNGn6Y287Mp6F+iteVlbVSdV1dcXO6Cq1lXVTFXNTExM7GrdkiSpo3Y3vPw7cCJwQ1Vtq6obgHvRCzAX725xkiRJg3Y3vFxO71tGnx5o+05VXbeb15YkSbqTVNW4a9hlMzMzNTc3N+4ypJ2TjLuC7unwf6ck7bgkl1TVzF0d5x12JUlSpxhepFGbnBx3Bd3iz0vSAHeVlkbNHZIlabc48iJJkjrFkRdJrbbmjAvHXcLIbDzrGeMuQeoER14kSVKnGF4kSVKnGF4kSVKntCa8JNky8Pr0JG8eVz2SJKmdWhNeJEmSdoThRZIkdUqbviq9f5L1fa/vDVwweFCSWWAWYHp6ekSlSZKktmjTyMvWqlq78AD+aLGDqmpdVc1U1czExMSIS5QkSePWpvAiSZJ0lwwvkiSpUwwvkiSpU1qzYLeqVg+8Phs4eyzFSJKk1nLkRZIkdUprRl4kaTHutCxpkCMvkiSpUwwvkiSpU5w2krpmago2bx53FaMzOQmbNo27Ckkt4siL1DV7UnCBPe/zSrpLhhdJktQpQwkvSbYlWd/3OKNpvyjJV5JcmuSzSdYOnPeoJJXkacOoS5Ikdd+w1rxsbTZXXMzzq2ouyQuA1wI/1dd3KvDJ5s//M6TaJElSh41z2uhi4OCFF0kCPAc4HfjpJPuNqS5JktRiwwov+w9MGz1vkWNOAN7X9/ongauragNwEfD0IdUmSZI6bBzTRu9IcndgFXB0X/upwHnN8/OAXwDeO3hykllgFmB6enrZCpYkSd2Qqlr+iyZbBjdabNovAl4KXAqcBfx4Vf1sklXANcBtwDYgwH2A+1XVzUu9z8zMTM3NzS17/VKrJeOuYPSG8N8pSe2T5JKqmrmr48ay5qWqbgNeATw2yUOApwKXVtUhVbWmqg4F3gOcNI76JElSew1r2mj/JOv7Xv9rVZ3Rf0BVbU3yOnojMauA8weu8R7g/wP+fkg1SpKkDhpKeKmqVUu0Hzfw+nXbucYFwAXLW5kkSeo677ArSZI6xfAidc3k5LgrGK097fNKukvuKi11jTssS9rDOfIiSZI6xfAiSZI6xWkjaSWYmoLNm8ddxXBMTjpVJukOHHmRVoKVGlxgZX82SbvE8CJJkjqlVdNGSbYBl/c1nVdVZ42rHkmS1D6tCi9sfzdqSZIkp40kSVK3tC287J9kfd/jeYMHJJlNMpdkbn5+fhw1SpKkMerctFFVrQPWAczMzNRIqpIkSa3RtpEXSZKk7TK8SJKkTmnbtNH+Sdb3vf7XqjpjbNVIkqTWaVV4qapV465BkiS1m9NGkiSpUwwv0kowOTnuCoZnJX+c9FWfAAAgAElEQVQ2SbukVdNGknaRuy5L2oM48iJJkjrFkRdJrbbmjAvHXcKy23jWM8ZdgtRpjrxIkqROMbxIkqROMbxIkqROWfbwkmRbsyP0pUk+l+TYpn1Nkq19fZ9KcsTAuW9Mck0SQ5UkSVrUMELC1qpaW1WPBF4GvKavb0Nf39uBly90NIHlZODrwBOHUJckSVoBhj3CcQ/gxh3sezLwBeB/A6cOuS5JktRRw/iq9MLmivsB9wOe0td3WNN3IHAAcExf36nAucD7gVcn2buqbhu8eJJZYBZgenp6COVLkqQ2G+a00ZHACcA5SdL0LUwbHQa8GFgHkGQf4OnA+6rqJuAzwE8vdvGqWldVM1U1MzExMYTyJUlSmw31JnVVdXGSg4DFUsYFwNua5ycA9wQub3LOAcAtwMq7O5UkSdotQw0vSY4EVgHX0wsk/R4PbGienwr8clWd25x3d+DqJAdU1S3DrFGSJHXLMNe8AAQ4raq2NSMqC2teAnwf+OUkBwBPA160cIGq+m6STwLPBN41hBolSVJHLXt4qapVS7RvBPZf4rR7L3L8zy5jWZIkaYVwY0ZJreYmhpIGeSdbSZLUKYYXSZLUKYYXSZLUKa55kVayqSnYvHncVeyeyUnYtGncVUhqEUdepJWs68EFVsZnkLSsDC+SJKlTxjJtlGQbcHlf00nAGnqbMv4XvU0dz6uqPx59dZIkqc3GteZla1Wt7W9Isgb4RFWd2GwPsD7JB6rqknEUKEmS2qmV00ZV9V3gEuCwcdciSZLaZVzhZf8k65vH+YOdSe4DPBa4YpG+2SRzSebm5+dHUaskSWqR1kwbNZ6Q5PPA7cBZVXWn8FJV64B1ADMzMzXcMiVJUtu07T4vn6iqE8ddhCRJaq9WrnmRJElaiuFFkiR1ylimjapq9SJtFwEXjbwYSZLUKY68SJKkTjG8SCvZ5OS4K9h9K+EzSFpWbfu2kaTl5G7MklYgR14kSVKnGF4k3dnUFCTteExNjfunIallDC+S7mzz5nFX8CNtqkVSKxheJElSpxheJElSpwz120ZJtgGXN+/zJeC0qrplB9oXnFRVG4dZoyRJ6pZhj7xsraq1VXUU8H3gV3ewfeGxccj1SZKkjhnltNEngAftRLskSdKdjCS8JLkb8N+445TQYu37J1nfPM5f4lqzSeaSzM3Pzw+1bkmS1D7DvsPu/knWN88/AfzdXbRvraq127tgVa0D1gHMzMzUMtcrSZJabtjhZakwcpchRZIkaTF+VVqSJHWK4UWSJHXKUMNLVa1ejnZJkqQFjrxIkqROMbxIurPJyXFX8CNtqkVSKwz720aSumjTpnFXIElLcuRFkiR1iuFF0uKmpiAZ/2Nqatw/CUktY3iRtLjNm8ddQU9b6pDUGoYXSZLUKSMPL0n2S/IfSS5NckWSP27aL0rylWZTxi8lmR11bZIkqf3G8W2jW4GnVNWWJHsDn0zywabv+VU1l+TewIYkZ1fV98dQoyRJaqmRh5eqKmBL83Lv5jG4O/Rq4LvAthGWJkmSOmAsa16SrEqyHrgW+Leq+kzT9Y4klwFfAf5HVd0pvCSZTTKXZG5+fn6EVUuSpDYYS3ipqm1VtRZ4APATSY5qup5fVY8ApoGXJjl0kXPXVdVMVc1MTEyMsGpJktQGY/22UVV9G7gIOGGgfR74HHDMGMqSJEktNo5vG00kuVfzfH/gqcCXB445AHgUsGHU9UmSpHYbx7eN7ge8PckqeuHp3VX1gSQvpbfmZSuwL3B2VV0yhvokSVKLjePbRpfRG1UZbD9u1LVIkqTu8Q67kiSpUwwvkhY3OTnuCnraUoek1hjHmhdJXbBp07grkKRFOfIiSZI6xZEXSa225owLx/beG896xtjeW9LSHHmRJEmdYniRJEmdYniRJEmdMvI1L0m2AZf3NZ1XVWcluYje3Xe/B3wf+JWqWj/q+iRJUruNY8Hu1mZH6cU8v6rmkrwAeC3wUyOsS5IkdUBbp40uBg4edxGSJKl9xhFe9k+yvu/xvEWOOQF432InJ5lNMpdkbn5+friVSpKk1mnbtNE7ktwdWAUcvdgBVbUOWAcwMzNTwylRkiS1VdumjZ4P/DjwTuB/jbkWSZLUQm0LL1TVbcArgMcmeci465EkSe3ShjUvZw0eUFVbgdcBLx19eZIkqc1GvualqlYt0X7cwOvXjaQgSZLUKa2bNpIkSdoed5WW1Gru7CxpkCMvkiSpUwwvkiSpU5w2ktRqa864cGzv7ZSV1E6OvEiSpE4xvEiSpE4ZWnhJsq25Cd2lST6X5NimfU2SrU3fF5P8VZK9BtoXHvsMqz5JktRNw1zz8sMNGJM8DXgN8KSmb0NVrU1yN+AjwEnA5xbah1iTJEnquFFNG90DuHGwsap+AHwKeNCI6pAkSR03zJGX/ZOsB/YD7gc8ZfCAJAcAxwN/1DQd1pwD8O9V9WtDrE+SJHXQqKaNHgeck+Sopm8hpBTw/qr6YJI17MC0UZJZYBZgenp6WLVLkqSWGsl9Xqrq4iQHARNN0y6vbamqdcA6gJmZmVqmEiVJUkeMZM1LkiOBVcD1o3g/SZK0co1izQtAgNOqaluSIb6lJEla6YYWXqpq1RLtG4GjdrRdkiSpn3fYlSRJneLGjJJazc0RJQ1y5EWSJHWK4UWSJHWK4UWSJHWK4UXSXZuagmQ8j6mpcX96SS1jeJF01zZv3jPfW1IrGV4kSVKnjDS8JNmWZH2SLyT55yT3Guh/SZLvJbnnKOuSJEndMeqRl61VtbaqjgJuAH5toP9U4LPAySOuS5IkdcQ4p40uBg5eeJHkMGA18Ap6IUaSJOlOxhJekqwCjgcu6Gs+FTgX+ARwRJL7LnHubJK5JHPz8/PDL1aSJLXKqMPLwk7T1wP3Bv6tr+8U4Lyquh14L/Bzi12gqtZV1UxVzUxMTAy9YEmS1C5jWfMCHArsQ7PmJckjgMOBf0uykV6QcepIkiTdyVimjarqO8BvAi9Nsje9oHJmVa1pHvcHDk5y6DjqkyRJ7TW2BbtV9XngUnqjLKcA5w8ccn7TLkmS9EN3G+WbVdXqgdfPbJ7+/SLH/vZIipIkSZ3iHXYlSVKnGF4k3bXJyT3zvSW10kinjSR11KZN465Akn7IkRdJktQpjrxIarU1Z1w4svfaeNYzRvZeknadIy+SJKlTDC+SJKlTxrUx4x8kuSLJZUnWJ/lgktcMHLM2yZfGUZ8kSWqvka95SfI44ETg6Kq6NclBwMOAtwEv6zv0FOCdo65PkiS12zhGXu4HXFdVtwJU1XVV9THg20mO6TvuucB5Y6hPkiS12DjCy4eAQ5JcmeQtSZ7UtJ9Ls5dRkscC11fVVWOoT5IktdjIw0tVbQEeDcwC88C7kpxOb5TlOUn2ohdizl3s/CSzSeaSzM3Pz4+oakmS1BZjWbBbVduq6qKqeiXw68Czq+rrwEbgScCzgXcvce66qpqpqpmJiYmR1SxJktph5OElyRFJDu9rWgt8tXl+LvAGYENVfWPUtUmSpPYbx8jLauDtSb6Y5DLgocCZTd8/0vvmkQt1JUnSokb+VemqugQ4dom+eWDv0VYkSZK6xDvsSpKkTnFjRkmt5maJkgY58iJJkjrF8CJJkjrF8CJJkjrFNS+SWm3NGRcO9fquqZG6x5EXSZLUKYYXSZLUKUMJL0m29D1/epKrkkwnOTPJNUnWJ/lykv/dbMRIkrOTXN3X98ph1CZJkrptqCMvSY4H3gScUFVfa5rfUFVr6W0L8HB6GzEu+N2mby1wWpIfH2Z9kiSpe4a2YDfJE4C/AZ5eVRsWOWQfYD/gxkX69mv+/O6QypMkSR01rJGXfYH3AydV1ZcH+l6SZD3wLeDKqlrf1/fapu8bwHlVde3ghZPMJplLMjc/Pz+k8iVJUlsNK7zcBnwKeOEifQvTRvcF7p7klL6+hWmjKeD4JHfawLGq1lXVTFXNTExMDKN2SZLUYsMKL7cDzwUek+Tlix1QVbcB/wo8cZG+LcBFwOOHVJ8kSeqooS3YrapbgBOB5ye50whMkgDHAndaD5PkbsAxi/VJkqQ921DvsFtVNyQ5Afh4kuua5pck+e/A3sBlwFv6TnltklfQW8z7YeC9w6xPkiR1z1DCS1Wt7nv+dWDhK8/vB85c4pzTh1GLJElaWbzDriRJ6hQ3ZpTUam6cKGmQIy+SJKlTDC+SJKlTnDaS1Gprzrhw2a7lFJS0MjjyIkmSOsXwIkmSOsXwIkmSOmWk4SXJtiTrk1ya5HMLGy8mWZNka1/fp5IcMcraJElSN4x65GVrVa2tqkcCLwNe09e3oa/v7cCiGzpKkqQ92zinje4B3LgLfZIkaQ826q9K759kPbAfcD/gKX19hzV9BwIH0NtV+k6SzAKzANPT08OtVpIktc64po2OBE4AzkmSpm9h2ugw4MXAusUuUFXrqmqmqmYmJiZGVLYkSWqLsU0bVdXFwEHAYgnkAuCJo61IkiR1wdjCS5IjgVXA9Yt0Px7YMNqKJElSF4xrzQtAgNOqalszc7Sw5iXA94FfHnFtkiSpA0YaXqpq1RLtG4H9R1mLJEnqJu+wK0mSOsVdpSW1mjtBSxrkyIskSeoUw4skSeoUw4uk5Tc1BcnyPKamxv1pJLWM4UXS8tu8uZ3XkrQiGF4kSVKnLHt4SbJl4PXpSd7cPD8zyTVJ1if5YpJTB469W5LrkrxmueuSJEkrwzhGXt5QVWuBZwF/nWTvvr6fBr4CPLdvw0ZJkqQfGufGjFcBtwA/1td8KvBG4GvAY8dRlyRJardh3KSuf/8igHvT2yX6DpIcDVxVVdc2r/cHjgdeBNyLXpC5eJHzZoFZgOnp6WUvXpIktdswRl62VtXahQfwRwP9L0nyFeAzwJl97ScCH62qW4D3ACcnudNeSFW1rqpmqmpmYmJiCOVLkqQ2G9ealyOA5wHnJNmvaT8VeGqSjcAlwH2AJ4+hPkmS1GLjXPPyXmAOOC3JPYDHA9NVtaaq1gC/Ri/QSJIk/dC4N2b8E+CdwG3AR6rq1r6+9wN/lmTfgXZJkrQHS1WNu4ZdNjMzU3Nzc+MuQ9Kg5b7TQYf/OyVpxyW5pKpm7uo477ArSZI6xfAiaflNTrbzWpJWhHGveZG0Em3aNO4KJK1gjrxIkqROMbxIWn5TU71Fu8vxmJoa96eR1DKGF0nLb/Pmdl5L0opgeJEkSZ1ieJEkSZ0y8vCSZCrJeUk2JPlikn9J8uAkf5nkC0kuT/LZJD8+6tokSVL7jfSr0kkCnA+8vapOadrW0tuk8f7AI6rq9iQPAL47ytokSVI3jHrk5cnAbVX1VwsNVbWeXlD5VlXd3rR9o6puHHFtkiSpA0YdXo4CLlmk/d3AM5OsT/K6JI9a6gJJZpPMJZmbn58fWqGSJKmdWrFgt6q+ARwBvAy4HfhwkuOXOHZdVc1U1czExMQoy5QkSS0w6u0BrgCes1hHVd0KfBD4YJLNwEnAh0dYmyRJ6oBRj7x8BNg3ya8sNCR5TJInJbl/83ov4BHAV0dcmyRJ6oCRhpeqKuBk4Kear0pfAZxJL6z8c5IvAJcBPwDePMraJElSN4x8V+mq+ibw3EW63jTqWiRJUve0YsGuJEnSjjK8SFp+k5PtvJakFWHk00aS9gCbNo27AkkrmCMvkiSpUwwvkoZjagqS3X9MTY37k0hqGcOLpOHYvLld15G0YhheJElSpwwlvCT5gyRXJLms2WzxmCT7JPmL5uZ0VyV5f5IHDJx3cpJKcuQw6pIkSd237OElyeOAE4Gjq+oRwFOBrwOvBg4EHlxVhwPvA96bJH2nnwp8EjhlueuSJEkrwzBGXu4HXNdstEhVXQd8G3gB8JKq2ta0vw24FXgKQJLVwE8CL8TwIkmSljCM8PIh4JAkVyZ5S5InAQ8CvlZVNw0cOwc8rHl+EvCvVXUlcEOSo4dQmyRJ6rhlDy9VtQV4NDALzAPvAp4M1CKHp6/9VOC85vl5zes7n5DMJplLMjc/P7+cpUuSpA5Ib6PnIb5B8hzgRcDRwJqqurmv7+PAHwPrgW8A19ILM6uaPw+t7RQ4MzNTc3NzQ6xe0i67w3K23TTk/05Jaockl1TVzF0dN4wFu0ckObyvaS3wFeDtwOuTrGqO+0XgAOAjwHOAc6rq0KpaU1WHAFcDj1/u+iRJUrcNY2+j1cCbktwL+AHwn/SmkG4G/hy4MsntwJeBk6uqkpwKnDVwnfcAPw98Ygg1SpKkjhr6tNEwOW0ktZjTRpJ20timjSRJkobJ8CJpOCYn23UdSSvGMNa8SBJs2jTuCiStUI68SJKkTjG8SJKkTnHaSFKrrTnjwt06f+NZz1imSiS1hSMvkiSpUwwvkiSpU0YaXpJMJTkvyYYkX0zyL0kenOTwJB9o2i9J8tEkTxxlbZIkqRtGFl6SBDgfuKiqDquqhwIvByaBC4F1Tfujgd8AHjiq2iRJUneMcuTlycBtVfVXCw1VtR54MHBxVV3Q1/6Fqjp7hLVJkqSOGGV4OQq4ZJH2hwGf29GLJJlNMpdkbn5+ftmKkyRJ3dC6BbtJzk/yhSTvXay/qtZV1UxVzUxMTIy6PEmSNGajDC9XAI9eov3ohRdVdTJwOnDv0ZQlSZK6ZJTh5SPAvkl+ZaEhyWOA/wR+MsnP9B17wAjrkiRJHTKy8FJVBZwM/FTzlegrgDOBbwInAr+a5L+SXAy8AvjTUdUmSZK6Y6TbA1TVN4HnLtH99FHWIkmSuql1C3YlSZK2x40ZJbWaGytKGuTIiyRJ6hTDiyRJ6hSnjSS12pozLtzhY51ikvYMjrxIkqROMbxIkqROGUt4SXJRkpnm+cYklzePLyb50yT7jqMuSZLUfiMPL0lWLdL85Kp6OPATwAOBdaOtSpIkdcV2F+wm+R/AdVX1xub1q4DNwL707pS7L3B+Vb2y6X8fcAiwH/DGqlrXtG8BXg88Dfidpd6vqrYk+VXg60nuXVU37ObnkyRJK8xdjbz8HXAaQJK9gFPohZfD6Y2SrAUeneSJzfG/VFWPBmaA30xyn6b97sAXquqYqvrk9t6wqm4Crm7eQ5Ik6Q62O/JSVRuTXJ/kUcAk8HngMcBPN88BVtMLGh+nF1hObtoPadqvB7YB79mJurJkRzILzAJMT0/vxCUlSdJKsCP3eflb4HRgCngrcDzwmqr66/6DkhwHPBV4XFXdkuQietNHAN+rqm07UlCSA4E1wJWL9TdTUesAZmZmakeuKUmSVo4dWbB7PvD/2rv/YMvruo7jz5fomrEpCReWgYWVQgSVVrjID1O2zAZ1o2aqGRpo2GxmR0cYs9RWmZIZ/yFtVAal2pR2ptaJhsxMFNaKzf4I7O6yLCwLtJAkKHC30Qpjlhbf/XHO1tnLXXapu9/P+d7zfMycmfv9fu738Dpf7t197efzPed7EYMZl1uHj3ckWQqQ5IQkxwIvA74zLC6vAs57vmGGz3k98IWq+s7zPV6SJC1+B515qaqnk9wGfHc4e7IpyenAPyQBeBK4DLgFeGeS7cD9wO3PI8dtGTzZCxiUpY88v5chSZImxUHLy/BC3fOAX9y3b/juo2vn+fa3zvccVbV0zvaqka9XHFpUSZKkgywbJTkD2AX8TVX9UzeRJEmSDuxg7za6l8GHxklSE95sUdJc3ttIkiT1iuVFkiT1iuVFkiT1yqF8SJ0kNbNi3c2H9H1eGyNNDmdeJElSr1heJElSrxyW8pLkyTnba5J8avj11UkeTbItyX1Jfm/4QXgk2ZDkn4djW5OcfzjySZKk/mo18/KJqloJnAG8FrhwZOz9w7F1wB/Md7AkSZpcrZeNljC48/R8N2H8GvCj3caRJEnj7nC92+glSbaNbL8c+OLI9nuTXAacDHylqrbxbD8D3D13Z5K1wFqAk046aeESS5KkXjhcMy9PVdXKfQ/gt+eM71s2OhY4MsklI2MfGxaftcCvzn3iqlpfVdNVNT01NXWY4kuSpHHVdNmoqv4LuAV408ju9w9Lz1uq6p5G0SRJ0phqWl6SBLgAeLBlDkmS1B+tyst7h0tD9zC47ub6RjkkSVLPHJYLdqtq6ZztDcCG4ddXA1cf4Lg1hyOPJElaPFq/VVqSJOl58caMksaaN1yUNJczL5IkqVcsL5IkqVdcNpI01lasu/mAYy4pSZPJmRdJktQrlhdJktQrlhdJktQrTcpLkquS7EiyPcm2JOcm2Zzk/uH2zuHdoyVJkvbT+QW7Sc4HVgNnVdWeJMcAS4bDl1bVTJKXAw8m2VBVT3edUZIkja8W7zY6HthdVXsAqmo3wOAejf9jKfA94JnO00mSpLHWYtloE7A8yQNJrk9y4cjYxiTbgfuBj1TVs8pLkrVJZpLMzM7OdpVZkiSNic7LS1U9CZwNrAVmgRuTrBkOX1pVZwInAe9LcvI8x6+vqumqmp6amuoqtiRJGhNNPqRuOKOyGdic5G7g8jnjs0m2AucCD3efUJIkjavOZ16SnJbk1JFdK5lTUJL8IPA64MEus0mSpPHXYuZlKXBdkqOAvcAuBktINzG45uUp4MXAhqra0iCfJEkaY52Xl2EhuWCeoVUdR5EkST3kjRkljTVvvihpLm8PIEmSesXyIkmSesXyIkmSesXyIml8LFsGyf6PZctap5I0ZiwvksbH448f2j5JE83yIkmSeqXT8pLkmSTbkuxIcleSX0/yguHYqiT/luTOJDuTfLjLbJIkqR+6/pyXp6pqJUCSY4HPAS8D9hWVv6+q1UmOBLYl+ZKfsitJkkY1WzaqqicY3BbgiiSZM/Y9YAvwIy2ySZKk8dX0mpeqemiY4djR/UmOBs4Ddsw9JsnaJDNJZmZnZ7sJKkmSxsY4XLA7OuvyxiR3ApuAa6rqWeWlqtZX1XRVTU9NTXUWUpIkjYem9zZKcgrwDPAEcDrDa15aZpIkSeOt2cxLking94FPVVW1yiFJkvql65mXlyTZBrwI2Av8MfDxjjNIkqQe67S8VNURzzG2GdjcWRhJktRL43DBriRJ0iGzvEgaH8cdd2j7JE20pu82kqT9PPZY6wSSesCZF0mS1CuWF0njY9kySPZ/LFvWOpWkMWN5kTQ+Hn/80PZJmmiWF0mS1CuWF0mS1Cstbw9wVZIdSbYn2Zbk3CSbk9w/3N6W5Bda5ZMkSeOpyVulk5wPrAbOqqo9SY4BlgyHL62qmRa5JEnS+Gv1OS/HA7urag9AVe0GSNIojiRJ6otWy0abgOVJHkhyfZILR8Y2jiwbHT33wCRrk8wkmZmdne0usSRJGgtNyktVPQmcDawFZoEbk6wZDl9aVSuHj3+d59j1VTVdVdNTU1PdhZYkSWOh2e0BquoZBneR3pzkbuDyVlkkSVJ/NJl5SXJaklNHdq0EHm6RRZIk9UurmZelwHVJjgL2ArsYLCHd1CiPJEnqiSblpaq2ABfMM7Sq4yiSJKln/IRdSZLUK5YXSePjuOMObZ+kidbs3UaS9CyPPdY6gaQecOZFkiT1iuVF0lhbse5mVqy7uXUMSWPE8iJJknrF8iJJknplwctLkquS7EiyfXhzxXOTbE4yPfI9K5LcM7L940m+nuS+4WPtQueSJEmLw4K+2yjJ+cBq4Kyq2pPkGGDJQY5ZBnwO+Lmq2jo85tYkj1aVC92SJGk/Cz3zcjywu6r2AFTV7qr61kGOeTewoaq27jsG+ACwboGzSZKkRWChy8smYHmSB5Jcn+TCkbGNw2WkbcCXR/a/Gtgy53lmhvslSZL2s6DlpaqeBM5mcJPFWeDGJGuGw5dW1cqqWgm8beSwADXf083330iyNslMkpnZ2dmFCy9JknphwS/YrapnqmpzVX0YuAL4+YMcsgOYnrPvbODeAzz/+qqarqrpqamp/39gSZLUKwtaXpKcluTUkV0rgYcPctingTVJVg6f42jgd4CPLmQ2SZK0OCz0vY2WAtclOQrYC+xisIR004EOqKpvJ7kM+MMkP8RgGemTVfVXC5xNkiQtAgtaXqpqC3DBPEOr5nzfN4DXjGx/DThnIbNIkqTFyU/YlSRJvbLQy0aStKC+cc3bW0eQNGaceZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb1ieZEkSb2Sqmqd4f8sySzwcOsch9ExwO7WIRqb9HMw6a8fPAe+/sl+/TBZ5+Dkqpo62Df1urwsdklmqmq6dY6WJv0cTPrrB8+Br3+yXz94DubjspEkSeoVy4skSeoVy8t4W986wBiY9HMw6a8fPAe+fnkO5vCaF0mS1CvOvEiSpF6xvEiSpF6xvPRAkiuT3J9kR5KPts7TSpL3Jakkx7TO0qUkH0tyX5LtSf4iyVGtM3UhyUXDn/tdSda1ztO1JMuT3JZk5/B3/z2tM7WQ5Igkdyb5UussXUtyVJKbhr//O5Oc3zrTuLC8jLkkPwH8LHBmVb0a+N3GkZpIshx4C/AvrbM08FXgNVV1JvAA8MHGeQ67JEcAnwbeCpwB/FKSM9qm6txe4Deq6nTgPODdE3gOAN4D7GwdopFrgVuq6lXAjzG55+FZLC/j713ANVW1B6Cqnmicp5VPAB8AJu4K86raVFV7h5u3Aye2zNOR1wO7quqhqnoa+FMGJX5iVNW3q2rr8Ov/YPAX1wltU3UryYnA24HPtM7StSQvBd4EfBagqp6uqu+2TTU+LC/j75XAG5PckeTvkpzTOlDXklwMPFpVd7XOMgbeAXyldYgOnAB8c2T7ESbsL+5RSVYArwPuaJukc59k8I+W77cO0sApwCzwR8Nls7SvS8wAAAHuSURBVM8kObJ1qHHxwtYBBEn+Glg2z9BVDP4f/TCDaeNzgD9Lckotsve4H+QcfAj46W4Tdeu5Xn9V/eXwe65isJSwsctsjWSefYvqZ/5QJVkK/Dnwa1X1763zdCXJauCJqtqSZFXrPA28EDgLuLKq7khyLbAO+K22scaD5WUMVNVPHWgsybuAzw/LyteTfJ/BTbpmu8rXhQOdgySvBV4B3JUEBksmW5O8vqoe6zDiYfVcPwMASS4HVgNvXmzF9QAeAZaPbJ8IfKtRlmaSvIhBcdlYVZ9vnadjbwAuTvI24AeAlyb5k6q6rHGurjwCPFJV+2bbbmJQXoTLRn3wBeAnAZK8EljC5NxdlKq6u6qOraoVVbWCwS/0WYupuBxMkouA3wQurqr/bJ2nI/8InJrkFUmWAJcAX2ycqVMZtPXPAjur6uOt83Stqj5YVScOf+8vAf52gooLwz/jvpnktOGuNwP3Now0Vpx5GX83ADckuQd4Grh8Qv7lrf/1KeDFwFeHs0+3V9U720Y6vKpqb5IrgFuBI4AbqmpH41hdewPwy8DdSbYN932oqr7cMJO6dSWwcVjgHwJ+pXGeseHtASRJUq+4bCRJknrF8iJJknrF8iJJknrF8iJJknrF8iJJknrF8iJJknrF8iJJknrlvwHpLk9mCsYv8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 648x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotCoef(grid.best_estimator_.named_steps['logisticregression'].coef_.ravel(), teamXRfecv.columns.values, \"Recursive Logistic Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-7.036924357663255, 'HR'),\n",
       " (-6.625482449619146, 'AB'),\n",
       " (-6.6141848915954204, 'KAB'),\n",
       " (-3.109465062071774, 'OBP'),\n",
       " (-2.7941485351420763, '2B'),\n",
       " (-2.4494347708324367, 'Bavg'),\n",
       " (-2.351617447877606, 'WHIP'),\n",
       " (-1.8420924545396962, 'ERA'),\n",
       " (-1.6863303763279949, 'E'),\n",
       " (-1.5003473655213166, 'FP'),\n",
       " (-1.0743482258364394, 'PPF'),\n",
       " (-1.0395195711502057, '3B'),\n",
       " (-0.9628521206127816, 'RA'),\n",
       " (-0.5694957715325358, 'HRA'),\n",
       " (-0.5665150745815707, 'CS'),\n",
       " (-0.5384656993535823, 'SOA'),\n",
       " (-0.15782043208397895, 'DP'),\n",
       " (-0.134702041757356, 'SF'),\n",
       " (0.06577517856719536, 'SHO'),\n",
       " (0.22119864480433, 'SB'),\n",
       " (0.3296785989976615, 'HBP'),\n",
       " (0.3450757600241421, 'yearID'),\n",
       " (0.4937915989463838, 'CG'),\n",
       " (0.6003658671023974, 'BB'),\n",
       " (0.7551466425650996, 'KBB'),\n",
       " (0.8515926714721628, 'SV'),\n",
       " (0.9651705793684918, 'BPF'),\n",
       " (0.985573862382609, 'ER'),\n",
       " (1.6716831400993013, 'BBA'),\n",
       " (1.8517864903675552, 'H'),\n",
       " (2.5502913276257457, 'HA'),\n",
       " (2.6162058905496726, 'IPouts'),\n",
       " (2.6886098326042855, 'R'),\n",
       " (4.205364585007596, 'OPS'),\n",
       " (7.050365927945748, 'SO'),\n",
       " (7.133813321326671, 'Slug')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(zip(grid.best_estimator_.named_steps['logisticregression'].coef_.ravel(), teamXRfecv.columns.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting SVM Fields\n",
    "For SVM models, the interpretation of field importance is not as straight forward. Non-linear SVM models create hyperplanes in  infinite dimensional space. To accomplish this the source data used in the analysis must be mapped to a higher dimentional space and as a result is very different from the original data. Because of this it is not possible to determine feature weights like we did with the logisitc regessions above.\n",
    "\n",
    "However, we can ...?\n",
    "\n",
    "**Dr. Larson mentions join plots, but I don't think these work very well or look very good for binary variables. Not sure what we want to do with these**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
