{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining - Mini Lab\n",
    "### Team 2 - Patricia Goresen, Jeffrey Lancon, Brychan Manry, George Sturrock\n",
    "#### June 17, 2018\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "#### Data Description\n",
    "The sujbect matter for this Lab assignment is team level data from the Lahman baseball database.  The database was described in detail during Lab 1.  The team summarized team level statistics generated in Lab 1 is used as the input data set for this study.  The team level data was summarized from approximately 30,000 rows of data from team level statistics dating back to 1970 and payroll data.  \n",
    "#### Objective\n",
    "The ultimate objective is to find the best model to predict if a team will make the Playoffs given the available statistical data.  To meet this objective, this section will examine three different models to determine which produce the best accuracy, recall and precision scores.  The three models are:  \n",
    "    - GridSearchCV Logistic Regression with manual variable reduction\n",
    "    - GridSearchCV Logistic Regression with recursive feature elimination\n",
    "    - Support Vector Machine\n",
    "#### Approach\n",
    "First, the input data set will have categorical features with little value (ball park name and disparate database identifiers) removed.  Features with near zero variance (such as games played) will also be removed.  Features which introduce leakage (such as Wins and how far a team progressed in the playoffs) will be removed as well.  The data will then be split into a explanatory (\"X\") and response (\"Y\") dataframes to feed into the different models.   \n",
    "\n",
    "The \"GridSearchCV Logistic Regression with manual feature reduction\" model will start begin remaining explanatory variables and use correlation scores, variable inflation factors and significance scores to manually reduce the number of features input into the regression function.\n",
    "\n",
    "The \"GridSearchCV Logistic Regression with recursive feature elimination\" and \"Support Vector Machine\" models will also have the remaining explanatory variables input into it's pipeline for analysis.  The team will allow the recursive feature elimination function and Support Vector Machine to determine which features to include in the end model on with no intervention.  \n",
    "\n",
    "Model accuracy, recall and precision will be used to determine which model yields the best results to predict whether or not a team will make the Major League Baseball Playoffs.  \n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team DF\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1296 entries, 0 to 1323\n",
      "Data columns (total 37 columns):\n",
      "Unnamed: 0    1296 non-null int64\n",
      "yearID        1296 non-null int64\n",
      "R             1296 non-null int64\n",
      "AB            1296 non-null int64\n",
      "H             1296 non-null int64\n",
      "2B            1296 non-null int64\n",
      "3B            1296 non-null int64\n",
      "HR            1296 non-null int64\n",
      "BB            1296 non-null float64\n",
      "SO            1296 non-null float64\n",
      "SB            1296 non-null float64\n",
      "CS            1296 non-null float64\n",
      "HBP           1296 non-null float64\n",
      "SF            1296 non-null float64\n",
      "RA            1296 non-null int64\n",
      "ER            1296 non-null int64\n",
      "ERA           1296 non-null float64\n",
      "CG            1296 non-null int64\n",
      "SHO           1296 non-null int64\n",
      "SV            1296 non-null int64\n",
      "IPouts        1296 non-null int64\n",
      "HA            1296 non-null int64\n",
      "HRA           1296 non-null int64\n",
      "BBA           1296 non-null int64\n",
      "SOA           1296 non-null int64\n",
      "E             1296 non-null int64\n",
      "DP            1296 non-null int64\n",
      "FP            1296 non-null float64\n",
      "BPF           1296 non-null int64\n",
      "PPF           1296 non-null int64\n",
      "WHIP          1296 non-null float64\n",
      "KBB           1296 non-null float64\n",
      "KAB           1296 non-null float64\n",
      "Bavg          1296 non-null float64\n",
      "Slug          1296 non-null float64\n",
      "OBP           1296 non-null float64\n",
      "OPS           1296 non-null float64\n",
      "dtypes: float64(15), int64(22)\n",
      "memory usage: 384.8 KB\n",
      "Team 2017\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 1294 to 1323\n",
      "Data columns (total 37 columns):\n",
      "Unnamed: 0    30 non-null int64\n",
      "yearID        30 non-null int64\n",
      "R             30 non-null int64\n",
      "AB            30 non-null int64\n",
      "H             30 non-null int64\n",
      "2B            30 non-null int64\n",
      "3B            30 non-null int64\n",
      "HR            30 non-null int64\n",
      "BB            30 non-null float64\n",
      "SO            30 non-null float64\n",
      "SB            30 non-null float64\n",
      "CS            30 non-null float64\n",
      "HBP           30 non-null float64\n",
      "SF            30 non-null float64\n",
      "RA            30 non-null int64\n",
      "ER            30 non-null int64\n",
      "ERA           30 non-null float64\n",
      "CG            30 non-null int64\n",
      "SHO           30 non-null int64\n",
      "SV            30 non-null int64\n",
      "IPouts        30 non-null int64\n",
      "HA            30 non-null int64\n",
      "HRA           30 non-null int64\n",
      "BBA           30 non-null int64\n",
      "SOA           30 non-null int64\n",
      "E             30 non-null int64\n",
      "DP            30 non-null int64\n",
      "FP            30 non-null float64\n",
      "BPF           30 non-null int64\n",
      "PPF           30 non-null int64\n",
      "WHIP          30 non-null float64\n",
      "KBB           30 non-null float64\n",
      "KAB           30 non-null float64\n",
      "Bavg          30 non-null float64\n",
      "Slug          30 non-null float64\n",
      "OBP           30 non-null float64\n",
      "OPS           30 non-null float64\n",
      "dtypes: float64(15), int64(22)\n",
      "memory usage: 8.9 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "team = pd.read_csv('~/7331_MiniLab/data/teams2Plus.csv')\n",
    "\n",
    "#Convert Y/N playoff flag to 1/0 indicator\n",
    "team['Playoff'] = team['Playoff'].map({'Y':1, 'N':0})\n",
    "\n",
    "#Drop records with missing values in the Playoff column\n",
    "team = team[np.isfinite(team['Playoff'])]\n",
    "team.Playoff = team.Playoff.astype(int)\n",
    "\n",
    "#Store all franchise IDs per row for future references\n",
    "allfranchID = team['franchID']\n",
    "\n",
    "#Create Y Response Variable DF\n",
    "teamY = team['Playoff']\n",
    "\n",
    "#Drop Categorial Columns with no predictive ability\n",
    "team = team.drop(['teamIDBR', 'teamIDlahman45', 'teamIDretro', 'G', 'teamID', 'Ghome', 'name', 'park', 'lgID', 'divID', 'salary', 'attendance', 'Playoff'], axis=1)\n",
    "\n",
    "#Drop Columns which introduce leakage\n",
    "team = team.drop(['LgWin', 'DivWin', 'WCWin', 'WSWin', 'W', 'L', 'Rank'], axis=1)\n",
    "\n",
    "#Create Cross Validation Object with 10 folds\n",
    "## Not necessary for this data set, but will code for practice\n",
    "cv = ShuffleSplit(n_splits = 10, test_size=0.80, random_state=0)\n",
    "\n",
    "#Also create Test set for 2017\n",
    "team2017 = team.loc[team['yearID'] == 2017]\n",
    "franchid2017 = team2017['franchID']\n",
    "\n",
    "#Drop last categorial column now that it has been preserved\n",
    "team = team.drop(['franchID'], axis=1)\n",
    "team2017 = team2017.drop(['franchID'], axis=1)\n",
    "\n",
    "#Create X Explanatory Variables DF\n",
    "teamX = team\n",
    "teamXRfecv = team\n",
    "teamXSVM = team\n",
    "\n",
    "print(\"Team DF\")\n",
    "team.info()\n",
    "#teamX_colNames = list(teamX)\n",
    "\n",
    "print(\"Team 2017\")\n",
    "team2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "yearID        0\n",
       "R             0\n",
       "AB            0\n",
       "H             0\n",
       "2B            0\n",
       "3B            0\n",
       "HR            0\n",
       "BB            0\n",
       "SO            0\n",
       "SB            0\n",
       "CS            0\n",
       "HBP           0\n",
       "SF            0\n",
       "RA            0\n",
       "ER            0\n",
       "ERA           0\n",
       "CG            0\n",
       "SHO           0\n",
       "SV            0\n",
       "IPouts        0\n",
       "HA            0\n",
       "HRA           0\n",
       "BBA           0\n",
       "SOA           0\n",
       "E             0\n",
       "DP            0\n",
       "FP            0\n",
       "BPF           0\n",
       "PPF           0\n",
       "WHIP          0\n",
       "KBB           0\n",
       "KAB           0\n",
       "Bavg          0\n",
       "Slug          0\n",
       "OBP           0\n",
       "OPS           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last check for NA values\n",
    "team.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CG   SV    -0.521343\n",
      "HRA  CG    -0.517123\n",
      "KBB  CG    -0.450180\n",
      "CS   KBB   -0.382289\n",
      "RA   CG    -0.330862\n",
      "              ...   \n",
      "BB   R      0.591727\n",
      "SB   CS     0.655180\n",
      "BB   OBP    0.668055\n",
      "HRA  RA     0.743288\n",
      "OBP  R      0.814649\n",
      "Length: 55, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Drop highly correlated, insignificant and high VIF columns.\n",
    "teamX = team.drop(['2B', '3B', 'BBA', 'DP', 'HR', 'yearID', 'WHIP', 'HA', 'HBP', 'Slug', 'SF', 'OPS', 'Bavg', 'SOA', 'KAB', 'SHO', 'FP', 'E', 'ER', 'IPouts', 'SO', 'BPF', 'PPF', 'Unnamed: 0', 'ERA', 'H'], axis=1)\n",
    "\n",
    "#Create correlation matrix\n",
    "teamCorrMat = teamX.corr()\n",
    "\n",
    "# Highest Correlation Pairs\n",
    "corrPairs = teamCorrMat.unstack().sort_values(kind=\"quicksort\")\n",
    "#- REMOVE DUPLICATES\n",
    "corrPairs = corrPairs[::2]\n",
    "corrPairs = corrPairs[corrPairs.index.get_level_values(0) != corrPairs.index.get_level_values(1)]\n",
    "with pd.option_context('display.max_rows',10):\n",
    "    print(corrPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Scale data\n",
    "scaler = StandardScaler()\n",
    "teamX_scaled = scaler.fit_transform(teamX)\n",
    "teamXRfecv_scaled = scaler.fit_transform(teamXRfecv)\n",
    "teamXSVM_scaled = scaler.fit_transform(teamXSVM)\n",
    "\n",
    "#Save as data frames\n",
    "df_teamX_scaled = pd.DataFrame(teamX_scaled)\n",
    "df_teamXRfecv_scaled = pd.DataFrame(teamXRfecv_scaled)\n",
    "df_teamXSVM_scaled = pd.DataFrame(teamXSVM_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Inflation Factors (VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.763863</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.429119</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.103875</td>\n",
       "      <td>BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.018539</td>\n",
       "      <td>SB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.429290</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.684300</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.163924</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.226288</td>\n",
       "      <td>SV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.865377</td>\n",
       "      <td>HRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.573488</td>\n",
       "      <td>KBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.514838</td>\n",
       "      <td>OBP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF Factor features\n",
       "0     8.763863        R\n",
       "1     3.429119       AB\n",
       "2     2.103875       BB\n",
       "3     2.018539       SB\n",
       "4     2.429290       CS\n",
       "5     5.684300       RA\n",
       "6     3.163924       CG\n",
       "7     2.226288       SV\n",
       "8     3.865377      HRA\n",
       "9     2.573488      KBB\n",
       "10    6.514838      OBP"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Credit to:\n",
    "###https://stats.stackexchange.com/questions/155028/how-to-systematically-remove-collinear-variables-in-python\n",
    "###https://etav.github.io/python/vif_factor_python.html\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "df2_vif = pd.DataFrame()\n",
    "df2_vif[\"VIF Factor\"] = [vif(df_teamX_scaled.values, i) for i in range(df_teamX_scaled.shape[1])]\n",
    "#df2_vif[\"features\"] = df_teamX_scaled.columns\n",
    "df2_vif[\"features\"] = teamX.columns\n",
    "df2_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Feature Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.244775\n",
      "         Iterations 8\n",
      "                        Results: Logit\n",
      "===============================================================\n",
      "Model:              Logit            No. Iterations:   8.0000  \n",
      "Dependent Variable: Playoff          Pseudo R-squared: 0.487   \n",
      "Date:               2018-06-16 19:41 AIC:              656.4562\n",
      "No. Observations:   1296             BIC:              713.2937\n",
      "Df Model:           10               Log-Likelihood:   -317.23 \n",
      "Df Residuals:       1285             LL-Null:          -618.03 \n",
      "Converged:          1.0000           Scale:            1.0000  \n",
      "-----------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z      P>|z|     [0.025    0.975]\n",
      "-----------------------------------------------------------------\n",
      "R        0.0278     0.0024   11.6525   0.0000    0.0231    0.0324\n",
      "AB      -0.0027     0.0005   -5.6880   0.0000   -0.0036   -0.0018\n",
      "BB      -0.0015     0.0018   -0.8383   0.4019   -0.0050    0.0020\n",
      "SB       0.0049     0.0036    1.3761   0.1688   -0.0021    0.0118\n",
      "CS      -0.0124     0.0096   -1.2863   0.1983   -0.0313    0.0065\n",
      "RA      -0.0199     0.0027   -7.2632   0.0000   -0.0252   -0.0145\n",
      "CG       0.0375     0.0113    3.3166   0.0009    0.0153    0.0597\n",
      "SV       0.1140     0.0171    6.6774   0.0000    0.0805    0.1474\n",
      "HRA     -0.0148     0.0059   -2.5169   0.0118   -0.0264   -0.0033\n",
      "KBB      0.9999     0.3386    2.9536   0.0031    0.3364    1.6635\n",
      "OBP      5.4485     4.6202    1.1793   0.2383   -3.6069   14.5039\n",
      "===============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Summary table with full model fit prior to scaling, cross validation or recursive \n",
    "#feature elimination.\n",
    "#Cursory check to verify feature significance\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model = sm.Logit(teamY, teamX)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit To:  https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "results = []\n",
    "\n",
    "def EvaluateClassifierEstimator(classifierEstimator, X, y, cv, model):\n",
    "   \n",
    "    #Perform cross validation \n",
    "    scores = cross_validate(classifierEstimator, teamX, teamY, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "    \n",
    "    results.append({'Model': model, 'Accuracy': Accavg, 'Precision': Preavg, 'Recall': Recavg})\n",
    "\n",
    "    return scoresResults\n",
    "\n",
    "def EvaluateClassifierEstimator2(classifierEstimator, X, y, cv):\n",
    "    \n",
    "    #Perform cross validation \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predictions = cross_val_predict(classifierEstimator, teamX, teamY, cv=cv)\n",
    "    \n",
    "    #model evaluation \n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    \n",
    "    #pass true test set values and predictions to classification_report\n",
    "    classReport = classification_report(Y,predictions)\n",
    "    confMat = confusion_matrix(Y,predictions)\n",
    "    acc = accuracy_score(Y,predictions)\n",
    "    \n",
    "    print (classReport)\n",
    "    print (confMat)\n",
    "    print (acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV Logistic Regression with Manual Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  88 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.8, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=8,\n",
       "       param_grid={'penalty': ['l2'], 'random_state': [0], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ['lbfgs'], 'max_iter': [100, 500], 'class_weight': ['balanced', 'none']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logisitic regression 10-fold cross-validation \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=regEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "#regGridSearch.fit(teamX, teamY)\n",
    "regGridSearch.fit(df_teamX_scaled, teamY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.50459148, -0.70137689, -0.14700291,  0.20347241, -0.21723472,\n",
       "        -1.94741016,  0.60250008,  1.04109258, -0.50570959,  0.46057074,\n",
       "         0.23396854]])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diplay the top model parameters\n",
    "regGridSearch.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.88187\n",
      "The average precision for all cv folds is: \t\t\t 0.73837\n",
      "The average recall for all cv folds is: \t\t\t 0.55804\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.887175</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.592391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888139</td>\n",
       "      <td>0.722892</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.886210</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.566845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.879460</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.877531</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.601036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.874638</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.575130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.484536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.888139</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.518325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.552083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.883317</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.558511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.887175   0.721854  0.592391\n",
       "1  0.888139   0.722892  0.631579\n",
       "2  0.886210   0.741259  0.566845\n",
       "3  0.879460   0.776000  0.500000\n",
       "4  0.877531   0.698795  0.601036\n",
       "5  0.874638   0.698113  0.575130\n",
       "6  0.868852   0.723077  0.484536\n",
       "7  0.888139   0.804878  0.518325\n",
       "8  0.885246   0.762590  0.552083\n",
       "9  0.883317   0.734266  0.558511"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the best parameters for our Linear Regression object\n",
    "classifierEst = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateClassifierEstimator(classifierEst, df_teamX_scaled, teamY, cv, \"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator GridSearch Prediction\n",
      "[0 1 0 ... 0 0 1]\n",
      "[[0.99360415 0.00639585]\n",
      " [0.10024467 0.89975533]\n",
      " [0.72467299 0.27532701]\n",
      " ...\n",
      " [0.99641667 0.00358333]\n",
      " [0.99623721 0.00376279]\n",
      " [0.24545058 0.75454942]]\n"
     ]
    }
   ],
   "source": [
    "#Predictions using Grid Search CV\n",
    "#print(\"Plain GridSearch Prediction\")\n",
    "#print(regGridSearch.predict(teamX))\n",
    "#print(regGridSearch.predict_proba(teamX))\n",
    "#print(regGridSearch.predict(df_teamX_scaled))\n",
    "#print(regGridSearch.predict_proba(df_teamX_scaled))\n",
    "\n",
    "#Is there a difference between .predict and .best_estimator_.predict?  Nope.\n",
    "print(\"Best Estimator GridSearch Prediction\")\n",
    "#print(regGridSearch.best_estimator_.predict(teamX))\n",
    "#print(regGridSearch.best_estimator_.predict_proba(teamX))\n",
    "print(regGridSearch.best_estimator_.predict(df_teamX_scaled))\n",
    "print(regGridSearch.best_estimator_.predict_proba(df_teamX_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV Logistic Regression with Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV Logistic Regression 1st Pass\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:    7.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Second Pass\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Ranking [13 19  1  1 17  1 11  4 15 12  1  1 10  2  1  1  1  1  5  1  9 18  1  8\n",
      " 20  1 14 21  7  6 16  1 22  3  1  1  1]\n",
      "Support [False False  True  True False  True False False False False  True  True\n",
      " False False  True  True  True  True False  True False False  True False\n",
      " False  True False False False False False  True False False  True  True\n",
      "  True]\n",
      "Number of Features: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.8, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'logisticregression__max_iter': [100, 500], 'logisticregression__random_state': [0], 'logisticregression__class_weight': ['balanced', 'none'], 'logisticregression__penalty': ['l2'], 'logisticregression__solver': ['lbfgs']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Credit to:  Jake Drew NC Education Data Set Analysis\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "print(\"RFECV Logistic Regression 1st Pass\")\n",
    "rfecvEstimator = LogisticRegression()\n",
    "\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced', 'none']\n",
    "              ,'random_state': [0]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfecvGridSearch = GridSearchCV(estimator=rfecvEstimator\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring='accuracy')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data using RFECV\n",
    "rfecvGridSearch.fit(df_teamXRfecv_scaled, teamY)\n",
    "\n",
    "#Use the best parameters for our RFECV Linear Regression object\n",
    "rfecvClassifierEst = rfecvGridSearch.best_estimator_\n",
    "\n",
    "print(\"Logistic Regression Second Pass\")\n",
    "#Recursive Feature Elimination\n",
    "rfecv = RFECV(estimator=rfecvClassifierEst, step=1, cv=cv, scoring='accuracy', verbose=1)\n",
    "#X_BestFeatures = rfecv.fit_transform(teamX, teamY)\n",
    "X_BestFeatures = rfecv.fit_transform(df_teamXRfecv_scaled, teamY)\n",
    "\n",
    "print(\"Ranking\", rfecv.ranking_)\n",
    "print(\"Support\", rfecv.support_)\n",
    "print(\"Number of Features:\", rfecv.n_features_)\n",
    "\n",
    "#create a pipeline to scale all of the data and perform logistic regression during each grid search step.\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "#Define a range of hyper parameters for grid search\n",
    "parameters = { 'logisticregression__penalty':['l2']\n",
    "              ,'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'logisticregression__class_weight': ['balanced','none']\n",
    "              ,'logisticregression__random_state': [0]\n",
    "              ,'logisticregression__solver': ['lbfgs']\n",
    "              ,'logisticregression__max_iter':[100,500]\n",
    "             }\n",
    "\n",
    "#Perform the grid search using accuracy as a metric during cross validation.\n",
    "grid = GridSearchCV(pipe, parameters, cv=cv, scoring='accuracy')\n",
    "\n",
    "#Use the best features from recursive feature elimination during the grid search\n",
    "#grid.fit(teamX, teamY)\n",
    "grid.fit(df_teamXRfecv_scaled, teamY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.86635\n",
      "The average precision for all cv folds is: \t\t\t 0.8098\n",
      "The average recall for all cv folds is: \t\t\t 0.36002\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.867888</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.876567</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.426316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.374332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.855352</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.288660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.867888</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.414508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.869817</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.419689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.864031</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.304124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.864031</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.340314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.862102</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.322917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.866924</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.372340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.867888   0.805195  0.336957\n",
       "1  0.876567   0.810000  0.426316\n",
       "2  0.868852   0.786517  0.374332\n",
       "3  0.855352   0.823529  0.288660\n",
       "4  0.867888   0.769231  0.414508\n",
       "5  0.869817   0.778846  0.419689\n",
       "6  0.864031   0.907692  0.304124\n",
       "7  0.864031   0.812500  0.340314\n",
       "8  0.862102   0.826667  0.322917\n",
       "9  0.866924   0.777778  0.372340"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the best parameters from RFECV for our Linear Regression object\n",
    "rfecvClassifierEst = grid.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "#EvaluateClassifierEstimator(classifierEst, teamX, teamY, cv)\n",
    "EvaluateClassifierEstimator(rfecvClassifierEst, df_teamXRfecv_scaled, teamY, cv, 'Rfecv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n",
      "[[0.98580662 0.01419338]\n",
      " [0.16887826 0.83112174]\n",
      " [0.75980895 0.24019105]\n",
      " ...\n",
      " [0.99476135 0.00523865]\n",
      " [0.99295833 0.00704167]\n",
      " [0.42323329 0.57676671]]\n"
     ]
    }
   ],
   "source": [
    "#print(grid.best_estimator_.predict(teamX))\n",
    "#print(grid.best_estimator_.predict_proba(teamX))\n",
    "print(grid.best_estimator_.predict(df_teamXRfecv_scaled))\n",
    "print(grid.best_estimator_.predict_proba(df_teamXRfecv_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8858024691358025\n",
      "precision: 0.835820895522388\n",
      "recall: 0.47058823529411764\n",
      "[[1036   22]\n",
      " [ 126  112]]\n"
     ]
    }
   ],
   "source": [
    "#SVM for consolidated team level baseball data created in Lab 1.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#teamX_scaled = scaler.fit_transform(teamX)\n",
    "\n",
    "#train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(df_teamXSVM_scaled, teamY)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(df_teamXSVM_scaled)\n",
    "\n",
    "acc = mt.accuracy_score(teamY,y_hat)\n",
    "conf = mt.confusion_matrix(teamY,y_hat)\n",
    "prec = mt.precision_score(teamY, y_hat)\n",
    "recall = mt.recall_score(teamY, y_hat)\n",
    "print('accuracy:', acc )\n",
    "print('precision:', prec)\n",
    "print('recall:', recall)\n",
    "print(conf)\n",
    "\n",
    "results.append({'Model': 'SVM', 'Accuracy': acc, 'Precision': prec, 'Recall': recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(485, 37)\n",
      "(485,)\n",
      "[258 227]\n"
     ]
    }
   ],
   "source": [
    "#look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# SVM based Prediction\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Summary\n",
    "All three planned models were sucessfully implemented as planned.  All models utilized cross validation to control results.  Stochastic Gradient Descent was not utilized for the support vector machine model as the size of the data set did not warrant it use.  Good results were achieved by all models.  The Support Vector Machine model ultimately produced the best results.  The results are summarized in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manual</td>\n",
       "      <td>0.881871</td>\n",
       "      <td>0.738372</td>\n",
       "      <td>0.558044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rfecv</td>\n",
       "      <td>0.866345</td>\n",
       "      <td>0.809795</td>\n",
       "      <td>0.360016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.885802</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  Precision    Recall\n",
       "0  manual  0.881871   0.738372  0.558044\n",
       "1   Rfecv  0.866345   0.809795  0.360016\n",
       "2     SVM  0.885802   0.835821  0.470588"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results[['Model', 'Accuracy', 'Precision', 'Recall']]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key References\n",
    "\n",
    "https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb\n",
    "https://github.com/jakemdrew/EducationDataNC/blob/master/2017/Models/2017ComparingSegregatedHighSchoolCampuses.ipynb (Logit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
